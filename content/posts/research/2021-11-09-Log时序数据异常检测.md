---
date: "2021-11-09T15:41:39"
title: "Log时序数据异常检测"
---

！！以下内容均摘自阿里云[SLS机器学习介绍](https://developer.aliyun.com/article/658497)，写得实在太好了。！！

## 1 背景

数量多：以阿里云神农系统为例，一台机器有3500多个时序数据，以5秒作为采样周期1000台集群计算，每秒钟会产生70W个点。

生成时序数据是为了对业务进行监控和报警，但这块目前非常依赖与人的经验，我们来看几个典型的问题：

#### 问题1：业务/交易走势异常发现

例如下图的监控中，在2分钟时间内流量大小下跌30%以上，在2分钟内后又迅速恢复：

<img src="https://raw.githubusercontent.com/zecoo/imgs/master/uPic/1539222853666-45c0cf98-f79b-44f3-bd9a-945708dbeab4.png" alt="undefined"  />

应对这种情况有几种典型做法：

1. 同环比，例如和上一周、上一天同一时刻比较，如果下降或上升一定大小（例如30%），则产生报警
2. 假设系统是平滑的，与上一时刻比较，如果有比较大差距则认为是巨大变化，产生报警【这是我们目前异常监测能做到的】
3. 通过统计建模估算大致走势，如果违背则认为是异常报警

这些方法有比较强的假设，并对数据的精度有较为严格的要求，在生产中容易产生误报。

#### 问题2：异常点发现

在分钟监控下，秒级监控中的毛刺

<img src="https://raw.githubusercontent.com/zecoo/imgs/master/uPic/1539224376078-3bfd794e-33ad-420f-9860-1be3f8590c96.png" alt="undefined"  />

#### 问题3：延时是否是正常

与Pangu团队交流时发现，Latency告警是一个很依赖经验的问题，无法使用例如业务量等传统时序建模手段。主要有几大原因：

1. Latency 在QPS等请求上升时，一般都是趋于稳定的
2. Latency 下降并不能说系统出了问题，有可能当前没有访问
3. Latency 上升可能和系统的压力、请求，机器负载相关，上升30%可能是请求多了排队引擎，并不是软件或系统Hang。

因此Latency是否正常判断，不能以单一要素维度去建模，要考虑到相关因素。

![1539226472380-b461ec1f-3b52-4324-8cbd-bf5b5461d2f8](https://raw.githubusercontent.com/zecoo/imgs/master/uPic/1539226472380-b461ec1f-3b52-4324-8cbd-bf5b5461d2f8.png)

#### 问题4：在大量实例中发现问题

案例1：在分布式系统下，我们希望所有的实例行为是否都符合预期的，是否有一些实例没有被调度到造成了浪费。

案例2：在安全建模中，会对需要对同一类人（例如同一个组织）进行行为建模，其中是否有局部的人行为异常（例如流量在非工作时间段非常大）

这两个案例都会需要从几千个、几十万个实例中去发现不一样的实例。传统的人肉判断方法会显得力不从心。

![undefined](https://raw.githubusercontent.com/zecoo/imgs/master/uPic/1539224740993-910e789c-18cd-4b12-895e-e5476f5e901a.png)

## 2 时序建模

### 2.1 工业级算法设计思路

工业级的思路和学术界的有什么不同？目前学术界的思路都还不知道。

1. 减小数据维度。通常时序数据是多维的，不仅仅是响应时间这一个维度。然而随着维度的增长，多时间序列异常异常检测的计算时间会快速增加。一般解决方法是做一些相关性分析，去除一些无关的维度。
2. 使用简单的线性判别。往往越复杂的模型意味着很难更泛化地拟合真实的数据，因此我们提倡在算法的设计上，选择较为简单的线性方法进行粗略的异常判别，后续再使用更精确的算法对子区间进行判别。
3. 尽量设计在线的算法。目前大多数异常检测方法均为静态方法，即对历史中特定段落的时间序列进行分析并得出结果。【再次中枪】然而在许多场景中时间序列是不断增长的，因此实时获得的时间序列中的异常同样迫切。
4. 并行思想改善性能。这个思想哪里都可以用到哈。
5. 时间和效果的trade-off。对于某些不需要高精度检测，但是实时性较强的环境，可以通过调整参数来达到相应的需求。

### 2.2 时序预测模型概况

![时序预测模型概况.png](https://raw.githubusercontent.com/zecoo/imgs/master/uPic/1537320565957-779fd084-3212-4363-a66b-4cfc4593bfd3.png)

- 统计模型预测：其中自回归和移动平均模型，主要代表算法是ARMA系列；使用二阶或三阶指数平滑算法，主要代表算法是Holt Winters；对于趋势和周期序列，主要利用序列分解策略，主要代表算法是STL；同时也有利用卡尔曼滤波和随机游走算法进行时序的预测；
- 机器学习模型预测：消除时序中的噪点，利用鲁棒性回归和相应的随机过程（泊松过程、高斯过程等）配合使用Robust Regression；局部学习算法Local Learning；还有针对历史数据进行建模，利用贝叶斯算法进行时序预测；
- 深度学习模型预测：利用递归神经网络RNN，以及LSTM模型，进行时序预测；同时还有利用VAE（Variance Auto Encoder）算法将时序数据利用编码器的方式去噪声，并利用网络的强大拟合能力对其中数据缺失等问题得以解决；改进WaveNet模型使用CNN的形式去模拟部分RNN的策略较好的利用曲线的局部特征进行预测；

### 2.3 拟解决问题

时间序列一般具有如下比较明显的特征：

1. 趋势性：数据呈现某种持续向上或向下的趋势或者规律
2. 季节性：数据呈现季节性，数据按照一定的规则进行往复出现
3. 随机性：一些采集过程中的噪声或一些不规则的波动

时间序列预测法用于短期、中期和长期预测。时间序列的本质特性是承认动态数据之间的相关性或依赖关系，这种相关性表征了系统的“动态”或“记忆”。如果这种相关性可用数学模型描述，则可有系统的过去及现在的取值预测其未来取值。

通过分析指标历史数据，判断未来一段时间指标趋势及预测值，常见有 Holt-Winters、时序数据分解（STL）、ARMA 系列算法。该算法技术可用于异常检测、容量预测、容量规划等场景。

## 参考

https://developer.aliyun.com/article/658497 （时序建模 by 阿里云）

