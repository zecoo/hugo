<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>paper on 暴躁老农</title>
    <link>https://zecoo.github.io/hugo/categories/paper/</link>
    <description>Recent content in paper on 暴躁老农</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 18 Jul 2020 00:00:00 +0800</lastBuildDate>
    
	<atom:link href="https://zecoo.github.io/hugo/categories/paper/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>microRCA 复现</title>
      <link>https://zecoo.github.io/hugo/posts/experiment/microrca-%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/experiment/microrca-%E5%A4%8D%E7%8E%B0/</guid>
      <description>istio官网给出的sidecar注入的方法：
kubectl label namespace sock-shop istio-injection=enabled  检测流量是否进入的promQL：
histogram_quantile(0.50, sum(irate(istio_request_duration_seconds_bucket{reporter=&amp;quot;source&amp;quot;, destination_workload_namespace=&amp;quot;sock-shop&amp;quot;}[1m])) by (destination_workload, source_workload, le))  复现工作终于取得了第一阶段的胜利，.scv文件的来源都弄清楚了。这就花了我快一周的时间。记录一下踩的坑：
Locust和Siege Locust的压测比较灵活，我用siege压测的话，单单压一个页面可能还可以满足，但是如果要压多个http接口，甚至还有带header的post，get请求之类的，siege就不能胜任了。
前期填坑过程 坑一：版本问题 Sock-shop本来自带压测的代码，用的就是Locust。但是由于版本问题，第一，locust的版本是老版本；第二，base64的版本也是老版本，导致basic-auth的header直接不能生成。这就…很难受了。新版本自己看着啃吧。
Locust也有很多坑，首先是版本的问题，我在网上搜到的资料大多都是1.0版本之前的，而1.0相对于对于之前的版本有很大的变化。我只能根据官网的document硬啃，特别是header的使用。这个坑着实让我填的心塞。
既然版本有问题，那我换回老版本行不行呢？换了locust的0.14.6版本，依旧是401错误。这就是debug的痛苦吧。
坑二：Basic-Auth的header login 在sock-shop的client.js里写了有一个xhr.setHttpRequest的东西，需要验证base64加密过的header。
beforeSend: function (xhr) { xhr.setRequestHeader(&amp;quot;Authorization&amp;quot;, &amp;quot;Basic &amp;quot; + btoa(username + &amp;quot;:&amp;quot; + password)); }  使用排除法缩小debug的范围。我用python原生的request来模拟登录，继续搜索相关内容，然后找到了request.get(url, auth={&amp;quot;username&amp;quot;,&amp;quot;password&amp;quot;})的方法可以通过basic-auth，试了一下果然可以。
事实证明可能是locust出了问题，我用python自带的request来模拟用户登录是可以成功的。代码如下：
import requests url = &#39;http://39.100.0.61:30001/login&#39; response = requests.get(url, auth=(&#39;b&#39;,&#39;b&#39;)) print(response.text)  返回值200，内容是：Cookie is set。
这说明什么问题，说明是我的base64加密出了问题。就出在basic-auth这个header上面，排除了sock-shop的bug。继续搜索之，于是就有了正解：
Locust模拟带Basic-Auth的header base64旧版本的basic-auth是这样构造的：
base64string = base64.encodestring(&#39;%s:%s&#39; % (&#39;user&#39;, &#39;password&#39;)).replace(&#39;\n&#39;, &#39;&#39;)  因为版本问题惨遭抛弃。</description>
    </item>
    
    <item>
      <title>LNCS subsubsection 插入数学公式</title>
      <link>https://zecoo.github.io/hugo/posts/paper/lncs-subsubsection-%E6%8F%92%E5%85%A5%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/lncs-subsubsection-%E6%8F%92%E5%85%A5%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</guid>
      <description>记一个在LNCS里用latex遇到的坑。
插入数学公式的时候遇到这样的报错：
Math formula deleted: Insufficient symbol fonts.  我查了一下，从这几个角度排查问题
 可能是导包的时候\usepackage{xxx}不支持数学公式 是不是$$和\begin{equation}的区别  查了半天都没有结果，还是在控制变量的情况下发现，subsubsection后面是无法插入数学公式。section和subsection就是可以的。原因是LNCS里的subsubsection是一个整体，而不是类似于paragraph的那种。如果有换行，而且是以段落的形式来体现subsubsection就可以插入数学公式。
那怎么调整LNCS里subsubsection的格式呢？参考这篇文章
参考 http://blog.sina.com.cn/s/blog_7851bb8501017zbm.html （subsubsection格式）</description>
    </item>
    
    <item>
      <title>从PageRank谈几篇RCA论文</title>
      <link>https://zecoo.github.io/hugo/posts/math/pagerank%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/math/pagerank%E4%BD%BF%E7%94%A8/</guid>
      <description>从论文说起 先来看看几篇核心方法类似的论文：
 Root Cause Detection in a Service-Oriented Architecture （SIGMETRICS 2013） MS-Rank: Multi-Metric and Self-Adaptive Root Cause Diagnosis for Microservice Applications （ICWS 2019） Root Cause Analysis of Latency Problems with End-to-End Tracing in Microservice Environments （ICWS 2020）  第一篇论文是早的，后面两篇论文都参考了这个论文。最诡异的是ICWS2020这篇，连算法和公式都没有改就敢直接投？这赤裸裸的抄袭好吧，就是把SOA的概念换成了ms的概念。
吐槽还没完，聊聊具体的方法吧。
找Anomaly的方法 其中都提到了PageRank，而且要注意不是不同的PageRank，而是Personalized PageRank（PPR）其实也就是Weighted PageRank（WPR）
其中的问题 RCD SOA这篇论文里写得很清楚了，如果某一个区域的PR值保持很低，那么surfer会停留在此区域，陷入僵局。那么就需要往后传递surfer，于是就有了backward edge。
而到了后面两篇论文这里就走了样，变成了forward transformation、backward transformation和self transformation。让人难以理解。
PageRank 用一个东西，抓住输入和输出。
输入 DAG的matrix，如果有n个节点，那么就是一个n*n的矩阵。nij表示节点i和节点j的连接关系。在PageRank中，如果一个节点i链接到节点j，那么nij=1。
以上这个输入不对。
基于随机游走的PageRank算法的输入应该是第一个节点。然后是节点和节点之间的相关度。
输出 n个节点的PageRank排序PR，范围是0-10，值越高表示重要性越高。
Weighted PageRank 传统的PR跳转到页面中提到的链接或者重新输入一个链接是通过设定一个固定概率。显然在已知关系度的网络里不太适用。所以把节点与节点之间的边作为权重的WPR就被提出来了。
而RCD SOA这篇论文里的backward，其实就是增强反向传递surfer的概率。也就是加强了反向边的权重。
至此，关于这几篇论文的方法是大致有一个了解了，实现起来emmm。感觉就凭我的代码水平，是块硬骨头，不知道现在该不该啃。
参考 https://www.jianshu.com/p/6af90342c3ba （简单代码讲解）</description>
    </item>
    
    <item>
      <title>Service Dependecy Graph Building</title>
      <link>https://zecoo.github.io/hugo/posts/paper/service-dependecy-graph-building/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/service-dependecy-graph-building/</guid>
      <description>开始之前 正式开始之前我问自己这样几个问题
 kiali是trace的一个可视化工具，那么我怎么才能拿到trace的原始数据呢？ istio的数据也都是prom给的，prom的metric之前已经看过了。怎么从prom的metric构造一个trace处理呢？  终于在今天得到了想要的答案：
首先，Prometheus和tracing没有关系。其次，trace的原始数据是jaeger提供的，具体是opentracing标准的链路追踪手段。
OK，继续深入吧。
Jaeger数据存储 关于agent怎么上报span，collector如何管理span我先不关心。我现在立刻马上想要拿到trace的原始数据，最起码是能让我能二次开发的那种数据。
数据一般呢，是存在数据库里的，而我的pod里并没有数据库相关的，那数据存在哪里呢？然后我就搜到了这样一个信息：
 Istio中Jaeger的数据临时存在内存中
 既然这样，Jaeger UI又是怎么抽取数据并graph展示的？会不会有Prometheus类似的api接口暴露出来？果然功夫不负有心人，让我找到了Jaeger的API：
Jaeger trace info Trace API 先提下Jaeger提供的接口，因为这个东西我曾经上Jaeger官网，告诉我/traces这个接口是获取trace信息的API。看看原文怎么说的哈：
 Jaeger UI communicates with Jaeger Query Service via JSON API. For example, a trace can be retrieved via GET request to https://jaeger-query:16686/api/traces/{trace-id-hex-string}. This JSON API is intentionally undocumented and subject to change.
 但是我只顾着一个劲撞南墙，基础概念都没有打好就老想着找捷径。恰好今天静下心来好好想了一下一个trace是什么，拿istio的productpage来说，一次访问网址http://istio-gateway:port/productpage的过程，其实就是一个完整的trace。
回到官网提供的API，也就是说我知道了trace-id，那么trace的信息就能得到了呀。而trace-id在UI里已经提供了。
Trace meta data 回到Jaeger UI，点进一个trace，查看JSON格式的数据，其实就是我需要的数据。详细来看看这个json数据里的span都有哪些内容：
{ &amp;quot;data&amp;quot;: [ { &amp;quot;traceID&amp;quot;: &amp;quot;aeb825de4ba82901d71fecb349727885&amp;quot;, &amp;quot;spans&amp;quot;: [ { &amp;quot;traceID&amp;quot;: &amp;quot;aeb825de4ba82901d71fecb349727885&amp;quot;, &amp;quot;spanID&amp;quot;: &amp;quot;22958c27bcc7f900&amp;quot;, &amp;quot;operationName&amp;quot;: &amp;quot;details.</description>
    </item>
    
    <item>
      <title>云计算雾计算和边缘计算</title>
      <link>https://zecoo.github.io/hugo/posts/paper/%E4%BA%91%E8%AE%A1%E7%AE%97%E9%9B%BE%E8%AE%A1%E7%AE%97%E5%92%8C%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/%E4%BA%91%E8%AE%A1%E7%AE%97%E9%9B%BE%E8%AE%A1%E7%AE%97%E5%92%8C%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/</guid>
      <description>参考 https://zhuanlan.zhihu.com/p/55937656 （雾计算的特点）
https://zhuanlan.zhihu.com/p/42066947 （雾计算和边缘计算的区别）
https://blog.csdn.net/robertsong2004/article/details/52203710 （吸尘器这个例子可以解释什么叫计算）</description>
    </item>
    
    <item>
      <title>ASL复现</title>
      <link>https://zecoo.github.io/hugo/posts/experiment/asl%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/experiment/asl%E5%A4%8D%E7%8E%B0/</guid>
      <description>贝叶斯优化扩容 记录下实验过程
一开始发现无论我用多大的并发去压测productpage，都是在压测的瞬间P90和P50陡增，但是不用任何扩容的操作，P90和P50都能立马降下来。如下图
可以看到每一次峰值就是我增加一个压测后立马出现的情况。但是不做任何操作立马回落到正常。
一开始考虑要么让物理机的CPU和Mem限制住，但是觉得这样开销太大了。要不试试把pod的CPU和Mem限制住？立即开干。查到了限制pod资源的方法：
spec: containers: - image: gcr.io/google_containers/serve_hostname imagePullPolicy: Always name: kubernetes-serve-hostname resources: limits: cpu: &amp;quot;1&amp;quot; #限制pod申请最大的cpu数量为1个cpu memory: 512Mi #申请内存最大值 requests: cpu: &amp;quot;0.5&amp;quot; #pod申请的cpu数量为0.5个cpu memory: 400Mi #申请内存的最小值  调整限制的大小，发现cpu给0.1，mem给100m是比较合适的。继续尝试实验，如下图
仔细解说一下哈：
17:41分的时候，我开了两个并发为200的压测，指标立马上去了。BO这时候在后台跑着呢，记录一下几次迭代的结果：
| iter | target | x | time : 2020-05-29 17:41:44 | 2 | -55.71 | 1.441 | Pod Count Set to: 1 | 3 | 8.421 | 0.000228 | Pod Count Set to: 1 | 4 | -70.</description>
    </item>
    
    <item>
      <title>Scenario Driven MS Decomposition</title>
      <link>https://zecoo.github.io/hugo/posts/paper/scenario-driven-ms-decomposition/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/scenario-driven-ms-decomposition/</guid>
      <description>场景驱动、自底向上的单体系统微服务拆分方法
评价 核心思想：把数据表之间紧密联系的聚在一起，作为拆分微服务的准则。
实际上是关于数据表的划分，微服务的其他方面比如class、method的划分没有提到。
AIBR 结合Scenario、Trace和Sql进行微服务拆分。
单体系统的微服务化拆分也可以借鉴传统软件模块化的思路和方法,已有不少这方面的研究
图1是整个流程图
 标记权重：对用例标记权重（对于一些使用频率较高的用例增加权重）用例权重增加，用例包含的trace中边的权重都增加 监控工具：Kieker，收集trace的工具 日志类型：被调用方法的签名、调用链 ID、调用时间、调用顺序 轨迹图：见下图图3 共享群组+关联度矩阵（后面会提） 数据表权重图（关联矩阵添加权重的结果，用于聚类） 数据图表聚类（GN社区聚类算法） 计算拆分开销（later） 拆分方案生产  拆分方法 图3也很关键，一个scenario数据访问的trace。
同样还有图4，数据库的相关度graph（later）
数据表关联度 表关联度高表示表A和表B在一个场景要同时使用的情况比较多。比如说注册要用到user表和profile表。登录也要用到这两个表。就说明user表和profile表的关联度较高。
 sql的权重 两个数据表之间的关联度  表A和表B的关联度 = Cscenario + Ctrace + Csql
Cscenario = 同时操作表A+表B的场景之和 / 操作表A或表B中任意一张表的场景之和，trace、sql同理
共享群组 共享度高表示一张表被多个场景使用，更倾向于单独拆分成一个微服务。比如account表在注册场景、下单场景都用到了，说明account表的共享度较高。
共享度 = Sscenario + Strace + Ssql
Sscenario = 操作表t的场景数量 / 总场景数量，trace、sql同理
共享表的数量 = 共享表占比 * 所有表的数量
那么共享表占比是如何计算出来的呢？（没有提，可能是共享度达到某个值以上的就算是共享表吧）
表依赖度 和关联度、共享度类似，表示表A对表B的依赖程度。那和关联度有什么区别呢…依赖度高，表A和表B更有可能有一种主从关系。见图6
Dscenario = 同时操作表A和表B的场景 / 操作表A的场景之和（Tb对Ta的依赖）
共享群组条件 Ta和Tb的相互依赖程度（Ta -&amp;gt; Tb + Tb -&amp;gt; Ta）大于某一个值</description>
    </item>
    
    <item>
      <title>Delta debug MS</title>
      <link>https://zecoo.github.io/hugo/posts/paper/delta-debug-ms/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/delta-debug-ms/</guid>
      <description> a triangular tract of sediment deposited at the mouth of a river, typically where it diverges into several outlets.  the fourth letter of the Greek alphabet ( Δ , δ ), transliterated as ‘d.’.  variation of a variable or function.  一组影响系统执行dimensions，高效找出导致错误的deltas。这里delta包括（deployment、enviromental、configurations）  四个dimensions：node、instance、configuration、sequence  node：分布式的服务器，未知性较多  instance：微服务的instance一般都是有状态的，如果没有处理好，相同的instance如果不是同样的状态就会出错。  configuration：docker的配置，k8s的配置，是挺恶心的，万一内存不够，就爆了  sequence：异步的invocation导致错误  微服务settings作为circumstances，就可以用delta bebugging了，db是一种简化和隔离错误案例的方法  Istio是微服务service mesh的？Istio可以部署在k8s里的  delta debugging的作用是找到min的deltas导致错误  controller：delta debugging的位置，是文章核心嗷  scheduler：根据容器状态选择test case去执行。queue，有可用资源就去跑测试  executor：根据所给的circumstances在docker上跑测试用例，返回测试结果  circumstance：4个dimension的组合  delta：两个cir之间的差异  delta db目的：通过最简单cir抽取导致错误的最小delta set  min setting：一个node，一个instance，默认conf（full memory），正确的seq  general setting：一个可能引起错误的cir  表示方法：0表示min setting，1表示general setting  seq的表示方法稍微复杂一点，0表示顺序执行，1表示逆序执行  seq能全覆盖，node、instance numbers可以放低一点要求  If the given failing test case still fails with the simplest circumstance, the failure can be thought to be caused by internal faults of related microservices  我们的目标是找到应用在min cir上导致ftc产生ftr的同时ptc产生ptr的deltas  atomic delta是什么意思？？  we partition the set of deltas X into n equal-sized partitions  13vm each 8-core cpu 24gb memory  36-63 deltas -》 1-2deltas  就是能分出到底是哪种问题  但是有个很重要的点就是要开发再确认bug   </description>
    </item>
    
    <item>
      <title>Graph-based RCA in SOA and MS</title>
      <link>https://zecoo.github.io/hugo/posts/paper/graph-based-rca-in-soa-and-ms/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/graph-based-rca-in-soa-and-ms/</guid>
      <description>Graph-based root cause analysis for service-oriented and microservice architectures
JSS 2020
2 RW RCA方法有以下大致分类
 model-based的RCA方法 Spectrum（也可以称之为Classification）方法。有人用ML来做 图的方法  2017年的Sieve，MS-Rank也提到了这篇论文。
3 Graph-based RCA 举一个Wordpress的例子，如果不做loadbalance，HAProxy的运行缓慢可能是其中某一个服务器负载过大。
Graph Modules Node：
Edge：网络连接的对象，例如一次TCP连接的双方
Attribute：收集到的信息，比如Anomaly、metric和log
系统有以下几个modules：
anomalous region module Extractor从system graph（系统的什么图？）中抽取一个子图，也就是anomalous region的子图。对于计算型的资源，选择异常节点周围2跳的所有节点作为子图，见图4。其他情况没提到233
pattern module 已经被标记为异常的节点，会作为计算相似度的模板。目的是为了对经常出现的异常做一个初始的集合，来避免冷启动的问题。（这里的冷启动是指异常区域没有可以对比相似度的对象）
similarity module 输入：1. 异常区域（anomaly region） 2. 异常模版（pattern）
输出：1. 相似度得分 2. 节点对应图（见图5）
4 Graph Similarity 都是自定义的相似度计算方法，包括两个图的相似度、两个节点的相似度、节点的属性相似度。
5 Monitoring and Building Graphs Prom做监控，cadvisor和node expoter作为监控agent。
构建图的过程其实是节点和节点连接的过程，TCP连接就可以构建一个边，由此创建调用图。
6 Evaluation 场景 不同的场景有不同的异常注入方式
 面向服务的场景 负载均衡场景 Kafka集群场景 Spark&amp;amp;HDFS场景  异常注入方式  stress做cpu、mem压力异常 连接异常（带宽限制） 负载均衡异常 高并发异常  Precision Training set的构建方式：异常注入的情况可以得到一些region啊，比如我用stress做异常测试，得到微服务m1出现异常，然后把m1周围2跳的节点抽取出来作为region。这就是一个新的pattern。</description>
    </item>
    
    <item>
      <title>Microscope</title>
      <link>https://zecoo.github.io/hugo/posts/paper/microscope-pinpoint-performance-issues-with-causal-graphs-in-micro-service-environments/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/microscope-pinpoint-performance-issues-with-causal-graphs-in-micro-service-environments/</guid>
      <description>Microscope: Pinpoint Performance Issues with Causal Graphs in Micro-service Environments
ICSOC 2018
Abstruct 错误定位的论文。通过服务调用关系构建DAG定位错误。
Introduction 定位有88%的准确性，2020的icws有一篇错误定位论文跟该论文进行过比较。
benchmark用的是sock shop
System Overview 三个步骤
 data collection 收集的是两个服务之间的网络连接和SLO metric（应该和SLA差不多） casual graph building 用收集到的数据构建一个casual graph（服务调用关系图？） rank cause inference 根据graph，列出所有root cause候选并排序  System design data collection 需要从“127.0.0.1:port -&amp;gt; 172.80.12.98:port”的调用关系map到“Service A instance1 -&amp;gt; Service B instance 1”
SLO可以从服务监控软件中获取到服务响应时间
casual graph building 如果是Service A到Service B的错误定位，1中已经提到了。
还有一种情况是Service内部instance和instance之间的关系，如果有一个instance占据了所有的cpu利用率，同一个service内的其他instance就不能和其他服务进行通信。本文采用PC-Algorithm构建DAG，一种用概率的方式来解决该问题。（细节需要去看PC-Algorithm的论文）
rank cause inference 通过一个异常的节点（前端报出的异常节点），遍历该节点下的所有子节点，然后把所有的异常子节点都加入到候选集中。
那么如何判断一个节点是否是异常节点？
3sigma interval规则，即正态分布的3sigma，如果一个node的metric落在了99.7%的范围之外，就认为其是abnormal。3sigma interval是多少呢？（后面提了一嘴：“The sample interval in service request latency metrics is 1s.</description>
    </item>
    
    <item>
      <title>RCA in multitier service</title>
      <link>https://zecoo.github.io/hugo/posts/paper/rca-in-multitier-service/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/rca-in-multitier-service/</guid>
      <description>Root Cause Analysis of Anomalies of Multitier Services in Public Clouds
TON 2018
读完感觉不像是A类的期刊，Chinglish的情况很严重，相似度的计算实在是不优美，最后baseline挑的也很奇怪。
IBR 这篇文章里用了一个很贴切的词：tenant，RCA用另一种解释其实就是tenant，也就是之前网易的面试官跟我说的profiling，是因为一个节点Root出现故障，导致和该节点有关的所有节点都变慢了。
这篇也是在前面会议论文的基础上加了一些内容投的期刊。
System Arch Anomaly Type 内在因素：服务调用过程中出现的异常
外在因素：在同一个物理机上的异常导致该物理机上不同的VM的异常
System 两部分，第一部分构建异常传播图（也是一个DAG），第二部分计算相似度Rank异常节点。
Graph VCG（VM Communication Graph）用工具PreciseTracer可以获得。
APG（Anomaly Propagation Graph）
Root Cause Location 这里面定义的相关度和其他不太一样，Sim(VMi, Rj)，是计算某个VM和某个请求之间的相关度。
Data Collection  服务响应时间，这里的计算方式是将所有参与一次响应的相关组件的响应时间相加 Utilization，比如CPU、mem等  都是老生常谈了
Similarity Calculation 依旧是皮尔逊相关系数，不过这个相关度也太复杂了吧？
R(i, M, R&amp;reg;, ts, te) = cov(Mte(M,i),Tte (R&amp;reg;)􏲊 / σMte (M,i)σTte (R&amp;reg;)
Random Walk 依旧是Forward、Backward和Self，就是随机游走哪一套
Evaluation Baseline  RS：Random Select，普通人用排列组合的方式选择 SC：Sudden Change，比较当前metric和一个时间窗口之前的metric的变化，变化最大的那个视为Anomaly DBR：Distance Based Rank，选择最优传播路径，找传播过程花费距离最短的  Evaluation Metric</description>
    </item>
    
    <item>
      <title>MS-Rank</title>
      <link>https://zecoo.github.io/hugo/posts/paper/ms-rank/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/ms-rank/</guid>
      <description>MS-Rank: Multi-Metric and Self-Adaptive Root Cause Diagnosis for Microservice Applications
ICWS 2019
主要贡献：  根据一系列的metrics，构建一个调用图
 基于随机游走算法提出了根因定位算法
 为了提高定位的准确性，用一种自适应的方法调整metrics的权重
  2 RW 提到了Microscope和Sieve
论文里居然还提到了SRE…hh
3 Solution 3A Framwork 针对不同的情景，选择的metric也不一样。UI相关的，一般更在意latency；计算相关的比如hadoop，更在意cpu负载。文章把微服务系统看成是一个黑盒，那么metric的权重这样的概念就出来了。
3B Metric latency适合短连接服务，但不适合长连接服务。
常见的metric：latency、throughput、CPU、MEM、disk、I/O，power。power = throughput / latency
Gradient相关重要的metric：
Gradient(t) = Mj,i(t) - Mji(t-1)
Gradient ratio(t) = Gradient(t) / Mj,i(t)
还有两个没列出来
3C Graph Construction 基于PC算法，依旧是一个DAG。额，这部分看得我一头雾水
3D Random Walk Diagnosis 一个最直观也是最常用的根因定位方法是计算某个服务的metric和Anomaly服务的metric的相似度。我看的其他论文里也大致是这个思想
同样这篇论文用皮尔逊相似度，不过添加了权重的部分。可以得到vi和vj的关系（相似度）
Transition（游走）：向前（遇到高相似度）、向内（前后都是低相似度，则停留在自身）、向后（遇到低相似度）
3E Weight Update P(M) Precision Function，计算定位结果的准确性。还有更新权重，都是一个公式带过。
3F Example 收集了2小时（7200s）的数据，每5s一次收集，对于每个metric都有1440个记录。</description>
    </item>
    
  </channel>
</rss>