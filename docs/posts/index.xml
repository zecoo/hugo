<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 暴躁老农</title>
    <link>https://zecoo.github.io/hugo/posts/</link>
    <description>Recent content in Posts on 暴躁老农</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 22 Dec 2020 00:00:00 +0800</lastBuildDate>
    
	<atom:link href="https://zecoo.github.io/hugo/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Istio中reporter=source和destination的区别</title>
      <link>https://zecoo.github.io/hugo/posts/istio/istio%E4%B8%ADreportersource%E5%92%8Cdestination%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/istio/istio%E4%B8%ADreportersource%E5%92%8Cdestination%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>以下是istio官网给出的区别：
 Reporter：这是请求报告者的标识符。报告从服务端 Istio 代理而来时设置为 destination，从客户端 Istio 代理而来时设置为 source。
 但是显然没有说人话。然后我又在Bing上面找了几个版本：
 reporter=&amp;quot;source&amp;quot; ：metric 报告来源，源服务（source）是 envoy 代理的下游客户端。在 服务网格 里，一个源服务通常是一个 工作负载 ，但是入口流量的源服务有可能包含其他客户端，例如浏览器，或者一个移动应用。 reporter=source就是来自于源Envoy，reporter=destination就是目标Envoy  甚至连例子都有了：
{destination_app=&amp;quot;sauron-seo-app&amp;quot;,reporter=&amp;quot;destination&amp;quot;,source_app=&amp;quot;consumer-gateway&amp;quot;} 58  这代表过去 24 小时里，从 consumer-gateway 到 sauron-seo-app 的请求中有 58 个出了问题，得到了 503UC 的结果，这一情况是由 sauron-seo-app 的 Envoy 汇报而来。
直到最后我突然想到探究一下响应时间究竟是个什么玩意儿，然后我就找到了这个：
 响应时间=网络传输时间（请求）+服务器处理时间（一层或是多层）+网络传输时间（响应）+页面前段解析时间
 那我一直讨论的其实就是数据从server返回的时间/数据从client发送的时间。在图里就是下面箭头表示的时间/上面箭头表示的时间。这个比值比较大的话，反映的其实是server处理数据的时间比较长。这…感觉我这个工作就太简单了啊。
结合istio官网给出的“从服务端 Istio 代理而来时设置为 destination，从客户端 Istio 代理而来时设置为 source。”似乎就能说得通了。
附上收集数据的PromQL：
histogram_quantile(0.50, sum(irate(istio_request_duration_seconds_bucket{reporter=&amp;quot;destination&amp;quot;, destination_workload_namespace=&amp;quot;sock-shop&amp;quot;}[1m])) by (destination_workload, source_workload, le))&#39;  参考 https://istio.io/latest/zh/docs/reference/config/policy-and-telemetry/metrics/ （官网）
https://blog.csdn.net/lyj0629/article/details/80207598 （响应时间包括）
https://www.cnblogs.com/bell1991/p/7007463.html （响应时间组成）</description>
    </item>
    
    <item>
      <title>microRCA 复现</title>
      <link>https://zecoo.github.io/hugo/posts/experiment/microrca-%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/experiment/microrca-%E5%A4%8D%E7%8E%B0/</guid>
      <description>istio官网给出的sidecar注入的方法：
kubectl label namespace sock-shop istio-injection=enabled  检测流量是否进入的promQL：
histogram_quantile(0.50, sum(irate(istio_request_duration_seconds_bucket{reporter=&amp;quot;source&amp;quot;, destination_workload_namespace=&amp;quot;sock-shop&amp;quot;}[1m])) by (destination_workload, source_workload, le))  复现工作终于取得了第一阶段的胜利，.scv文件的来源都弄清楚了。这就花了我快一周的时间。记录一下踩的坑：
Locust和Siege Locust的压测比较灵活，我用siege压测的话，单单压一个页面可能还可以满足，但是如果要压多个http接口，甚至还有带header的post，get请求之类的，siege就不能胜任了。
前期填坑过程 坑一：版本问题 Sock-shop本来自带压测的代码，用的就是Locust。但是由于版本问题，第一，locust的版本是老版本；第二，base64的版本也是老版本，导致basic-auth的header直接不能生成。这就…很难受了。新版本自己看着啃吧。
Locust也有很多坑，首先是版本的问题，我在网上搜到的资料大多都是1.0版本之前的，而1.0相对于对于之前的版本有很大的变化。我只能根据官网的document硬啃，特别是header的使用。这个坑着实让我填的心塞。
既然版本有问题，那我换回老版本行不行呢？换了locust的0.14.6版本，依旧是401错误。这就是debug的痛苦吧。
坑二：Basic-Auth的header login 在sock-shop的client.js里写了有一个xhr.setHttpRequest的东西，需要验证base64加密过的header。
beforeSend: function (xhr) { xhr.setRequestHeader(&amp;quot;Authorization&amp;quot;, &amp;quot;Basic &amp;quot; + btoa(username + &amp;quot;:&amp;quot; + password)); }  使用排除法缩小debug的范围。我用python原生的request来模拟登录，继续搜索相关内容，然后找到了request.get(url, auth={&amp;quot;username&amp;quot;,&amp;quot;password&amp;quot;})的方法可以通过basic-auth，试了一下果然可以。
事实证明可能是locust出了问题，我用python自带的request来模拟用户登录是可以成功的。代码如下：
import requests url = &#39;http://39.100.0.61:30001/login&#39; response = requests.get(url, auth=(&#39;b&#39;,&#39;b&#39;)) print(response.text)  返回值200，内容是：Cookie is set。
这说明什么问题，说明是我的base64加密出了问题。就出在basic-auth这个header上面，排除了sock-shop的bug。继续搜索之，于是就有了正解：
Locust模拟带Basic-Auth的header base64旧版本的basic-auth是这样构造的：
base64string = base64.encodestring(&#39;%s:%s&#39; % (&#39;user&#39;, &#39;password&#39;)).replace(&#39;\n&#39;, &#39;&#39;)  因为版本问题惨遭抛弃。</description>
    </item>
    
    <item>
      <title>LNCS subsubsection 插入数学公式</title>
      <link>https://zecoo.github.io/hugo/posts/paper/lncs-subsubsection-%E6%8F%92%E5%85%A5%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/lncs-subsubsection-%E6%8F%92%E5%85%A5%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</guid>
      <description>记一个在LNCS里用latex遇到的坑。
插入数学公式的时候遇到这样的报错：
Math formula deleted: Insufficient symbol fonts.  我查了一下，从这几个角度排查问题
 可能是导包的时候\usepackage{xxx}不支持数学公式 是不是$$和\begin{equation}的区别  查了半天都没有结果，还是在控制变量的情况下发现，subsubsection后面是无法插入数学公式。section和subsection就是可以的。原因是LNCS里的subsubsection是一个整体，而不是类似于paragraph的那种。如果有换行，而且是以段落的形式来体现subsubsection就可以插入数学公式。
那怎么调整LNCS里subsubsection的格式呢？参考这篇文章
参考 http://blog.sina.com.cn/s/blog_7851bb8501017zbm.html （subsubsection格式）</description>
    </item>
    
    <item>
      <title>ALL in ONE</title>
      <link>https://zecoo.github.io/hugo/posts/all-in-one/</link>
      <pubDate>Fri, 03 Jul 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/all-in-one/</guid>
      <description>这是一个类似于inbox的东西，乱七八糟的内容都会放进来
 https://www.instana.com/blog/no-root-cause-microservice-applications/
“Root cause is used to describe the depth in the causal chain where an intervention could reasonably be implemented to improve performance or prevent an undesirable outcome.” [Wikipedia]
Classical application performance management (APM) tools were build to find the single root cause of a problem. This worked well with static 3-tier and SOA architectures but as we have learned from complex system theory, this doesn’t work anymore in modern webscale and microservice based environments.</description>
    </item>
    
    <item>
      <title>从PageRank谈几篇RCA论文</title>
      <link>https://zecoo.github.io/hugo/posts/math/pagerank%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/math/pagerank%E4%BD%BF%E7%94%A8/</guid>
      <description>从论文说起 先来看看几篇核心方法类似的论文：
 Root Cause Detection in a Service-Oriented Architecture （SIGMETRICS 2013） MS-Rank: Multi-Metric and Self-Adaptive Root Cause Diagnosis for Microservice Applications （ICWS 2019） Root Cause Analysis of Latency Problems with End-to-End Tracing in Microservice Environments （ICWS 2020）  第一篇论文是早的，后面两篇论文都参考了这个论文。最诡异的是ICWS2020这篇，连算法和公式都没有改就敢直接投？这赤裸裸的抄袭好吧，就是把SOA的概念换成了ms的概念。
吐槽还没完，聊聊具体的方法吧。
找Anomaly的方法 其中都提到了PageRank，而且要注意不是不同的PageRank，而是Personalized PageRank（PPR）其实也就是Weighted PageRank（WPR）
其中的问题 RCD SOA这篇论文里写得很清楚了，如果某一个区域的PR值保持很低，那么surfer会停留在此区域，陷入僵局。那么就需要往后传递surfer，于是就有了backward edge。
而到了后面两篇论文这里就走了样，变成了forward transformation、backward transformation和self transformation。让人难以理解。
PageRank 用一个东西，抓住输入和输出。
输入 DAG的matrix，如果有n个节点，那么就是一个n*n的矩阵。nij表示节点i和节点j的连接关系。在PageRank中，如果一个节点i链接到节点j，那么nij=1。
以上这个输入不对。
基于随机游走的PageRank算法的输入应该是第一个节点。然后是节点和节点之间的相关度。
输出 n个节点的PageRank排序PR，范围是0-10，值越高表示重要性越高。
Weighted PageRank 传统的PR跳转到页面中提到的链接或者重新输入一个链接是通过设定一个固定概率。显然在已知关系度的网络里不太适用。所以把节点与节点之间的边作为权重的WPR就被提出来了。
而RCD SOA这篇论文里的backward，其实就是增强反向传递surfer的概率。也就是加强了反向边的权重。
至此，关于这几篇论文的方法是大致有一个了解了，实现起来emmm。感觉就凭我的代码水平，是块硬骨头，不知道现在该不该啃。
参考 https://www.jianshu.com/p/6af90342c3ba （简单代码讲解）</description>
    </item>
    
    <item>
      <title>Demo: flask&#43;vue&#43;mysql</title>
      <link>https://zecoo.github.io/hugo/posts/server/demo-flask&#43;vue&#43;mysql/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/server/demo-flask&#43;vue&#43;mysql/</guid>
      <description>从本科软工教学谈起 这样一套前后端都打通的demo，才算是真的接触到软件工程的皮毛吧？
今天在想本科的教学，根本不管学生的水平差距，只让学生分几个组，做一个高大上的东西出来。于是就出现了疯狂抱大腿的现象，并不是说这样不好。我们可以说那些混子你怎么自己不努力呀，只想着抱大腿？我经历过所以我知道那个时候的自己还没有成熟，不知道什么是对自己好的，什么是不好的。抱大腿做一个fancy的项目出来意味着高分数，意味着高GPA，意味着可能拿奖学金、保研。
但是选择了抱大腿，就可能去做一些边缘的东西，比如美工、比如前端、比如产品。对于一个基本的产品全貌是没有办法掌握的。
而且本科学Java、学数据库、学计算机网络等等，我不知道自己为什么学，只知道专业里有这么几门课程，而且要拿高分。就成了为了学而学，不管我为什么要学。我觉得如果让我大一的时候就接触前后端加数据库的最小demo，哪怕是一个hello world，我也会对整个框架有一定的概念，带着兴趣和疑问去听课。
怪自己，也怪老师们不了解学生水平。浪费了本科的大好时光，也就渐渐离程序员这个职业选择越来越远。
Hello World 回顾基础  Vue把后台的数据渲染到html里，就能实现动态网页 Flask处理数据，就是一些乱七八糟的后台逻辑 Mysql把数据存储起来，不然老是放内存里丢了怎么办。  环境配置 安装Vue环境 按照参考文章安装即可。
在心动实习的时候接触过Vue，当时用Electron做app，感觉运行过程特别缓慢。因为npm install要安装一大堆的module，整个项目就变得巨大。
安装Flask Flask如果想直接flask run运行的话，文件的命名方式必须为app.py，不然会提示先设置FLASK_PATH。
axios Vue里的模块，这个小东西类似Ajax，用于获取后台数据。
CORS Flask里的模块，如果没有它就不会把数据暴露出去。反正我没有暴露接口的话会报500错误。详细的等想起来了或者需要了再去研究。
运行流程 先用flask把接口暴露出来
@app.route(&#39;/getMsg&#39;) def get_msg(): response = { &#39;msg&#39;: &#39;hello python&#39; } return jsonify(response)  然后axios获取数据
const path = &#39;http://127.0.0.1:5000/getMsg&#39;; axios.get(path).then(function(response){ var msg = response.data.msg; console.log(msg); that.serverResponse = msg; })  连接mysql是python的事情，Flask拿数据就好了。
from pymysql import connect def conn_mysql(): conn = connect(host=&#39;localhost&#39;, port=3306, user=&#39;root&#39;, password=&#39;pwd&#39;, database=&#39;test&#39;) cur = conn.</description>
    </item>
    
    <item>
      <title>python应用环境搭建</title>
      <link>https://zecoo.github.io/hugo/posts/server/python%E5%BA%94%E7%94%A8%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/server/python%E5%BA%94%E7%94%A8%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <description>安装python3 首先下载python3安装包，在csdn上下载可能更快一点。
如果是在服务器上安python3，那可能需要修改镜像源。
app依赖 由于代码里需要import很多依赖，如果直接跑python app.py就会报各种依赖不存在的错误，所以需要先安装所有的依赖：pip install -r requirements.txt
参考 https://www.cnblogs.com/Simple-Small/p/12221135.html （安装python3）
https://github.com/shiniao/mini_sms_classify （python应用需要import的依赖）
https://blog.csdn.net/timtian008/article/details/81186356 （国内python下载太慢了）</description>
    </item>
    
    <item>
      <title>Service Dependecy Graph Building</title>
      <link>https://zecoo.github.io/hugo/posts/paper/service-dependecy-graph-building/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/service-dependecy-graph-building/</guid>
      <description>开始之前 正式开始之前我问自己这样几个问题
 kiali是trace的一个可视化工具，那么我怎么才能拿到trace的原始数据呢？ istio的数据也都是prom给的，prom的metric之前已经看过了。怎么从prom的metric构造一个trace处理呢？  终于在今天得到了想要的答案：
首先，Prometheus和tracing没有关系。其次，trace的原始数据是jaeger提供的，具体是opentracing标准的链路追踪手段。
OK，继续深入吧。
Jaeger数据存储 关于agent怎么上报span，collector如何管理span我先不关心。我现在立刻马上想要拿到trace的原始数据，最起码是能让我能二次开发的那种数据。
数据一般呢，是存在数据库里的，而我的pod里并没有数据库相关的，那数据存在哪里呢？然后我就搜到了这样一个信息：
 Istio中Jaeger的数据临时存在内存中
 既然这样，Jaeger UI又是怎么抽取数据并graph展示的？会不会有Prometheus类似的api接口暴露出来？果然功夫不负有心人，让我找到了Jaeger的API：
Jaeger trace info Trace API 先提下Jaeger提供的接口，因为这个东西我曾经上Jaeger官网，告诉我/traces这个接口是获取trace信息的API。看看原文怎么说的哈：
 Jaeger UI communicates with Jaeger Query Service via JSON API. For example, a trace can be retrieved via GET request to https://jaeger-query:16686/api/traces/{trace-id-hex-string}. This JSON API is intentionally undocumented and subject to change.
 但是我只顾着一个劲撞南墙，基础概念都没有打好就老想着找捷径。恰好今天静下心来好好想了一下一个trace是什么，拿istio的productpage来说，一次访问网址http://istio-gateway:port/productpage的过程，其实就是一个完整的trace。
回到官网提供的API，也就是说我知道了trace-id，那么trace的信息就能得到了呀。而trace-id在UI里已经提供了。
Trace meta data 回到Jaeger UI，点进一个trace，查看JSON格式的数据，其实就是我需要的数据。详细来看看这个json数据里的span都有哪些内容：
{ &amp;quot;data&amp;quot;: [ { &amp;quot;traceID&amp;quot;: &amp;quot;aeb825de4ba82901d71fecb349727885&amp;quot;, &amp;quot;spans&amp;quot;: [ { &amp;quot;traceID&amp;quot;: &amp;quot;aeb825de4ba82901d71fecb349727885&amp;quot;, &amp;quot;spanID&amp;quot;: &amp;quot;22958c27bcc7f900&amp;quot;, &amp;quot;operationName&amp;quot;: &amp;quot;details.</description>
    </item>
    
    <item>
      <title>云计算雾计算和边缘计算</title>
      <link>https://zecoo.github.io/hugo/posts/paper/%E4%BA%91%E8%AE%A1%E7%AE%97%E9%9B%BE%E8%AE%A1%E7%AE%97%E5%92%8C%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/%E4%BA%91%E8%AE%A1%E7%AE%97%E9%9B%BE%E8%AE%A1%E7%AE%97%E5%92%8C%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/</guid>
      <description>参考 https://zhuanlan.zhihu.com/p/55937656 （雾计算的特点）
https://zhuanlan.zhihu.com/p/42066947 （雾计算和边缘计算的区别）
https://blog.csdn.net/robertsong2004/article/details/52203710 （吸尘器这个例子可以解释什么叫计算）</description>
    </item>
    
    <item>
      <title>网页中英文字体新手使用</title>
      <link>https://zecoo.github.io/hugo/posts/blog/%E7%BD%91%E9%A1%B5%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AD%97%E4%BD%93%E6%96%B0%E6%89%8B%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/blog/%E7%BD%91%E9%A1%B5%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AD%97%E4%BD%93%E6%96%B0%E6%89%8B%E4%BD%BF%E7%94%A8/</guid>
      <description>关于中英文字体 一开始我天真地以为一套字体能够满足我中英文混排的需求。就是一套字体，包括中文和英文，而且中英文放在一起也不违和。事实证明我的确是太天真了。
设计一套英文字体本来就是一件非常费时间精力的事情，中文字体更是了。所以一般英文字体里不会有中文，中文字体里可能有英文。
字体渲染顺序 像这样一段css代码：
font-family: Helvetica, &amp;quot;微软雅黑&amp;quot;, sans-serif;  Helvetica是英文字体，微软雅黑是中文字体。系统碰到第一字，如果是中文，那么会先加载第一个字体Helvetica，发现不支持中文，于是转向下一个字体，发现雅黑支持中文，就渲染出来了。就这样依据顺序，如果系统里没有上述字体，就会用浏览器默认的，一般是宋体。
博客字体美观化 中文字体呢，我就选择微软雅黑，但是默认的微软雅黑字重是regular的400，看起来比较笨。我把字重改成了300，立马高级了一些。
英文字体呢，我觉得Arial和Tahoma都还挺好看的，但是他们最细的字重也要400了，和300的中文字体放在一起实在不搭。于是最后选择了Helvetica，意外还挺香。
参考 http://yanue.net/post-54.html （常见英文字体预览）</description>
    </item>
    
    <item>
      <title>ASL复现</title>
      <link>https://zecoo.github.io/hugo/posts/experiment/asl%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/experiment/asl%E5%A4%8D%E7%8E%B0/</guid>
      <description>贝叶斯优化扩容 记录下实验过程
一开始发现无论我用多大的并发去压测productpage，都是在压测的瞬间P90和P50陡增，但是不用任何扩容的操作，P90和P50都能立马降下来。如下图
可以看到每一次峰值就是我增加一个压测后立马出现的情况。但是不做任何操作立马回落到正常。
一开始考虑要么让物理机的CPU和Mem限制住，但是觉得这样开销太大了。要不试试把pod的CPU和Mem限制住？立即开干。查到了限制pod资源的方法：
spec: containers: - image: gcr.io/google_containers/serve_hostname imagePullPolicy: Always name: kubernetes-serve-hostname resources: limits: cpu: &amp;quot;1&amp;quot; #限制pod申请最大的cpu数量为1个cpu memory: 512Mi #申请内存最大值 requests: cpu: &amp;quot;0.5&amp;quot; #pod申请的cpu数量为0.5个cpu memory: 400Mi #申请内存的最小值  调整限制的大小，发现cpu给0.1，mem给100m是比较合适的。继续尝试实验，如下图
仔细解说一下哈：
17:41分的时候，我开了两个并发为200的压测，指标立马上去了。BO这时候在后台跑着呢，记录一下几次迭代的结果：
| iter | target | x | time : 2020-05-29 17:41:44 | 2 | -55.71 | 1.441 | Pod Count Set to: 1 | 3 | 8.421 | 0.000228 | Pod Count Set to: 1 | 4 | -70.</description>
    </item>
    
    <item>
      <title>Cool Sites</title>
      <link>https://zecoo.github.io/hugo/posts/blog/cool-sites/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/blog/cool-sites/</guid>
      <description> 同学  小崔：本科一起混日协的编程大佬 曹真：本科毕业pdd做推荐系统…  个人站点  DIYgod：前端大神 shud.in：设计师 花生A：自制挺有意思的站点 matrix67：搞数学的人是真的帅 四火：真实的程序员hh 石鸟：从restful的todo找到的在读研究生 张怡：宝藏女孩 羡辙杂俎：像素风个人站点 nanshu：about页的喜欢和不喜欢太可爱了 敖小剑：ServiceMesh布道者 绿色：记忆生活编程记录 MY：这简历太好看了  公司  Splayer：射手是个超nice的公司  博客  编程小栈：喜欢记录的在读生 进阶女学霸：图相关的研究  </description>
    </item>
    
    <item>
      <title>Istio sites</title>
      <link>https://zecoo.github.io/hugo/posts/istio/istio-sites/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/istio/istio-sites/</guid>
      <description>APP
 productpage sockshop hipser  Istio
 Prometheus Grafana Jaeger Kiali (admin,admin)  </description>
    </item>
    
    <item>
      <title>Start LeetCode</title>
      <link>https://zecoo.github.io/hugo/posts/math/start-leetcode/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/math/start-leetcode/</guid>
      <description>仅做个人记录，解题思路请看其他大佬的。
参考 https://labuladong.gitbook.io/algo/shu-ju-jie-gou-xi-lie/suan-fa-xue-xi-zhi-lu （如何学算法）
https://leetcode.com/explore/learn/card/fun-with-arrays/ （leetcode官网）
https://github.com/MisterBooo/LeetCodeAnimation （动画演示）</description>
    </item>
    
    <item>
      <title>Send file from one server to another</title>
      <link>https://zecoo.github.io/hugo/posts/server/send-file-from-one-server-to-another/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/server/send-file-from-one-server-to-another/</guid>
      <description>我没有想到传文件这么方便。那这样我有一台国外的服务器，可以做很多事情了啊。
参考 https://www.cnblogs.com/gudongcheng/p/8064808.html （scp）</description>
    </item>
    
    <item>
      <title>Scenario Driven MS Decomposition</title>
      <link>https://zecoo.github.io/hugo/posts/paper/scenario-driven-ms-decomposition/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/scenario-driven-ms-decomposition/</guid>
      <description>场景驱动、自底向上的单体系统微服务拆分方法
评价 核心思想：把数据表之间紧密联系的聚在一起，作为拆分微服务的准则。
实际上是关于数据表的划分，微服务的其他方面比如class、method的划分没有提到。
AIBR 结合Scenario、Trace和Sql进行微服务拆分。
单体系统的微服务化拆分也可以借鉴传统软件模块化的思路和方法,已有不少这方面的研究
图1是整个流程图
 标记权重：对用例标记权重（对于一些使用频率较高的用例增加权重）用例权重增加，用例包含的trace中边的权重都增加 监控工具：Kieker，收集trace的工具 日志类型：被调用方法的签名、调用链 ID、调用时间、调用顺序 轨迹图：见下图图3 共享群组+关联度矩阵（后面会提） 数据表权重图（关联矩阵添加权重的结果，用于聚类） 数据图表聚类（GN社区聚类算法） 计算拆分开销（later） 拆分方案生产  拆分方法 图3也很关键，一个scenario数据访问的trace。
同样还有图4，数据库的相关度graph（later）
数据表关联度 表关联度高表示表A和表B在一个场景要同时使用的情况比较多。比如说注册要用到user表和profile表。登录也要用到这两个表。就说明user表和profile表的关联度较高。
 sql的权重 两个数据表之间的关联度  表A和表B的关联度 = Cscenario + Ctrace + Csql
Cscenario = 同时操作表A+表B的场景之和 / 操作表A或表B中任意一张表的场景之和，trace、sql同理
共享群组 共享度高表示一张表被多个场景使用，更倾向于单独拆分成一个微服务。比如account表在注册场景、下单场景都用到了，说明account表的共享度较高。
共享度 = Sscenario + Strace + Ssql
Sscenario = 操作表t的场景数量 / 总场景数量，trace、sql同理
共享表的数量 = 共享表占比 * 所有表的数量
那么共享表占比是如何计算出来的呢？（没有提，可能是共享度达到某个值以上的就算是共享表吧）
表依赖度 和关联度、共享度类似，表示表A对表B的依赖程度。那和关联度有什么区别呢…依赖度高，表A和表B更有可能有一种主从关系。见图6
Dscenario = 同时操作表A和表B的场景 / 操作表A的场景之和（Tb对Ta的依赖）
共享群组条件 Ta和Tb的相互依赖程度（Ta -&amp;gt; Tb + Tb -&amp;gt; Ta）大于某一个值</description>
    </item>
    
    <item>
      <title>vps搭建图床</title>
      <link>https://zecoo.github.io/hugo/posts/blog/vps%E6%90%AD%E5%BB%BA%E5%9B%BE%E5%BA%8A/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/blog/vps%E6%90%AD%E5%BB%BA%E5%9B%BE%E5%BA%8A/</guid>
      <description>展示一下我的图床已经搭起来了。放一张我在心动实习的时候想设计的一个todo app：
参考 https://www.jianshu.com/p/7863fcb34aed</description>
    </item>
    
    <item>
      <title>Monitoring with log and trace</title>
      <link>https://zecoo.github.io/hugo/posts/paper/monitoring-with-log-and-trace/</link>
      <pubDate>Thu, 21 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/monitoring-with-log-and-trace/</guid>
      <description>Microservices Monitoring with Event Logs and Black Box Execution Tracing
TSC 2019
Chaper1 理解log一般需要专家，文章提出一个novel的方式帮助troubleshooting的决策 Clearwater IP Multimedia Subsystem 和 hipster差不多，都是有十多个微服务的玩意儿 嗯，微服务decomposed，非常适合monitoring，同时也有挑战 indirect monitoring 检测cpu之类的什么东西，direct monitoring可以直接在代码里插入log function进行monitoring。event log属于direct monitoring 现有的log management tool应该用的是正则和关键词查找的方式做分析，但是好像不是特别适合微服务。毕竟不同的系统，分析规则是不一样的 吹一波作者的monitoring工具MetroFunnel，不需要改变现有的微服务，也不需要对现有的系统有特别深刻的了解。
Chapter2 介绍indirect monitoring和direct monitoring，了解一下即可。Zipkin就是direct monitoring的方法
Chapter3 给了很多例子 第一个例子的错误是clearwater客户尝试拨打语音电话发生错误 ClearWater IP Multimedia Subsystem IMS IP多媒体子系统 安装 bono是IMS的一个微服务，负责客户端。同时发现sprout和bono接近，也是间接和客户端有关。又转向另一个微服务homestead，在这个里面找到了error，但是也没有说为什么就找到了homestead。这一章就讲了在不同的微服务里debug，结果还没说清楚微服务是怎么进行选择的。fk 有用的log比较少，在ms里情况更甚。
Chapter4 Goals tracing tech应该第一，不会产生新的服务；第二，不会对代码有影响；第三，没有很重的配置文件。 还有一些non-goals作者讲得很清楚。
Chapter5 感觉内容挺多？ 因为微服务一般都是用REST形式的api，就可以通过抓包的形式，也就是passive tracing的方式来进行monitoring，但这在之前的一些论文中已经有体现了。
Format of trace trace是代表微服务调用结果的记录序列。一般包含很多信息，比如时间戳、地址、ip、response code等，文章都有列出来
Tracing algorithm Tracing Algorithm有两个要点，
第一个是capture packets。简单判断一下就可以，正常的发送是GET /test/users/1这样的。接收到的是这样的HTTP/1.</description>
    </item>
    
    <item>
      <title>Delta debug MS</title>
      <link>https://zecoo.github.io/hugo/posts/paper/delta-debug-ms/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/delta-debug-ms/</guid>
      <description> a triangular tract of sediment deposited at the mouth of a river, typically where it diverges into several outlets.  the fourth letter of the Greek alphabet ( Δ , δ ), transliterated as ‘d.’.  variation of a variable or function.  一组影响系统执行dimensions，高效找出导致错误的deltas。这里delta包括（deployment、enviromental、configurations）  四个dimensions：node、instance、configuration、sequence  node：分布式的服务器，未知性较多  instance：微服务的instance一般都是有状态的，如果没有处理好，相同的instance如果不是同样的状态就会出错。  configuration：docker的配置，k8s的配置，是挺恶心的，万一内存不够，就爆了  sequence：异步的invocation导致错误  微服务settings作为circumstances，就可以用delta bebugging了，db是一种简化和隔离错误案例的方法  Istio是微服务service mesh的？Istio可以部署在k8s里的  delta debugging的作用是找到min的deltas导致错误  controller：delta debugging的位置，是文章核心嗷  scheduler：根据容器状态选择test case去执行。queue，有可用资源就去跑测试  executor：根据所给的circumstances在docker上跑测试用例，返回测试结果  circumstance：4个dimension的组合  delta：两个cir之间的差异  delta db目的：通过最简单cir抽取导致错误的最小delta set  min setting：一个node，一个instance，默认conf（full memory），正确的seq  general setting：一个可能引起错误的cir  表示方法：0表示min setting，1表示general setting  seq的表示方法稍微复杂一点，0表示顺序执行，1表示逆序执行  seq能全覆盖，node、instance numbers可以放低一点要求  If the given failing test case still fails with the simplest circumstance, the failure can be thought to be caused by internal faults of related microservices  我们的目标是找到应用在min cir上导致ftc产生ftr的同时ptc产生ptr的deltas  atomic delta是什么意思？？  we partition the set of deltas X into n equal-sized partitions  13vm each 8-core cpu 24gb memory  36-63 deltas -》 1-2deltas  就是能分出到底是哪种问题  但是有个很重要的点就是要开发再确认bug   </description>
    </item>
    
    <item>
      <title>Graph-based RCA in SOA and MS</title>
      <link>https://zecoo.github.io/hugo/posts/paper/graph-based-rca-in-soa-and-ms/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/graph-based-rca-in-soa-and-ms/</guid>
      <description>Graph-based root cause analysis for service-oriented and microservice architectures
JSS 2020
2 RW RCA方法有以下大致分类
 model-based的RCA方法 Spectrum（也可以称之为Classification）方法。有人用ML来做 图的方法  2017年的Sieve，MS-Rank也提到了这篇论文。
3 Graph-based RCA 举一个Wordpress的例子，如果不做loadbalance，HAProxy的运行缓慢可能是其中某一个服务器负载过大。
Graph Modules Node：
Edge：网络连接的对象，例如一次TCP连接的双方
Attribute：收集到的信息，比如Anomaly、metric和log
系统有以下几个modules：
anomalous region module Extractor从system graph（系统的什么图？）中抽取一个子图，也就是anomalous region的子图。对于计算型的资源，选择异常节点周围2跳的所有节点作为子图，见图4。其他情况没提到233
pattern module 已经被标记为异常的节点，会作为计算相似度的模板。目的是为了对经常出现的异常做一个初始的集合，来避免冷启动的问题。（这里的冷启动是指异常区域没有可以对比相似度的对象）
similarity module 输入：1. 异常区域（anomaly region） 2. 异常模版（pattern）
输出：1. 相似度得分 2. 节点对应图（见图5）
4 Graph Similarity 都是自定义的相似度计算方法，包括两个图的相似度、两个节点的相似度、节点的属性相似度。
5 Monitoring and Building Graphs Prom做监控，cadvisor和node expoter作为监控agent。
构建图的过程其实是节点和节点连接的过程，TCP连接就可以构建一个边，由此创建调用图。
6 Evaluation 场景 不同的场景有不同的异常注入方式
 面向服务的场景 负载均衡场景 Kafka集群场景 Spark&amp;amp;HDFS场景  异常注入方式  stress做cpu、mem压力异常 连接异常（带宽限制） 负载均衡异常 高并发异常  Precision Training set的构建方式：异常注入的情况可以得到一些region啊，比如我用stress做异常测试，得到微服务m1出现异常，然后把m1周围2跳的节点抽取出来作为region。这就是一个新的pattern。</description>
    </item>
    
    <item>
      <title>Microscope</title>
      <link>https://zecoo.github.io/hugo/posts/paper/microscope-pinpoint-performance-issues-with-causal-graphs-in-micro-service-environments/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/microscope-pinpoint-performance-issues-with-causal-graphs-in-micro-service-environments/</guid>
      <description>Microscope: Pinpoint Performance Issues with Causal Graphs in Micro-service Environments
ICSOC 2018
Abstruct 错误定位的论文。通过服务调用关系构建DAG定位错误。
Introduction 定位有88%的准确性，2020的icws有一篇错误定位论文跟该论文进行过比较。
benchmark用的是sock shop
System Overview 三个步骤
 data collection 收集的是两个服务之间的网络连接和SLO metric（应该和SLA差不多） casual graph building 用收集到的数据构建一个casual graph（服务调用关系图？） rank cause inference 根据graph，列出所有root cause候选并排序  System design data collection 需要从“127.0.0.1:port -&amp;gt; 172.80.12.98:port”的调用关系map到“Service A instance1 -&amp;gt; Service B instance 1”
SLO可以从服务监控软件中获取到服务响应时间
casual graph building 如果是Service A到Service B的错误定位，1中已经提到了。
还有一种情况是Service内部instance和instance之间的关系，如果有一个instance占据了所有的cpu利用率，同一个service内的其他instance就不能和其他服务进行通信。本文采用PC-Algorithm构建DAG，一种用概率的方式来解决该问题。（细节需要去看PC-Algorithm的论文）
rank cause inference 通过一个异常的节点（前端报出的异常节点），遍历该节点下的所有子节点，然后把所有的异常子节点都加入到候选集中。
那么如何判断一个节点是否是异常节点？
3sigma interval规则，即正态分布的3sigma，如果一个node的metric落在了99.7%的范围之外，就认为其是abnormal。3sigma interval是多少呢？（后面提了一嘴：“The sample interval in service request latency metrics is 1s.</description>
    </item>
    
    <item>
      <title>RCA in multitier service</title>
      <link>https://zecoo.github.io/hugo/posts/paper/rca-in-multitier-service/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/rca-in-multitier-service/</guid>
      <description>Root Cause Analysis of Anomalies of Multitier Services in Public Clouds
TON 2018
读完感觉不像是A类的期刊，Chinglish的情况很严重，相似度的计算实在是不优美，最后baseline挑的也很奇怪。
IBR 这篇文章里用了一个很贴切的词：tenant，RCA用另一种解释其实就是tenant，也就是之前网易的面试官跟我说的profiling，是因为一个节点Root出现故障，导致和该节点有关的所有节点都变慢了。
这篇也是在前面会议论文的基础上加了一些内容投的期刊。
System Arch Anomaly Type 内在因素：服务调用过程中出现的异常
外在因素：在同一个物理机上的异常导致该物理机上不同的VM的异常
System 两部分，第一部分构建异常传播图（也是一个DAG），第二部分计算相似度Rank异常节点。
Graph VCG（VM Communication Graph）用工具PreciseTracer可以获得。
APG（Anomaly Propagation Graph）
Root Cause Location 这里面定义的相关度和其他不太一样，Sim(VMi, Rj)，是计算某个VM和某个请求之间的相关度。
Data Collection  服务响应时间，这里的计算方式是将所有参与一次响应的相关组件的响应时间相加 Utilization，比如CPU、mem等  都是老生常谈了
Similarity Calculation 依旧是皮尔逊相关系数，不过这个相关度也太复杂了吧？
R(i, M, R&amp;reg;, ts, te) = cov(Mte(M,i),Tte (R&amp;reg;)􏲊 / σMte (M,i)σTte (R&amp;reg;)
Random Walk 依旧是Forward、Backward和Self，就是随机游走哪一套
Evaluation Baseline  RS：Random Select，普通人用排列组合的方式选择 SC：Sudden Change，比较当前metric和一个时间窗口之前的metric的变化，变化最大的那个视为Anomaly DBR：Distance Based Rank，选择最优传播路径，找传播过程花费距离最短的  Evaluation Metric</description>
    </item>
    
    <item>
      <title>MS-Rank</title>
      <link>https://zecoo.github.io/hugo/posts/paper/ms-rank/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/paper/ms-rank/</guid>
      <description>MS-Rank: Multi-Metric and Self-Adaptive Root Cause Diagnosis for Microservice Applications
ICWS 2019
主要贡献：  根据一系列的metrics，构建一个调用图
 基于随机游走算法提出了根因定位算法
 为了提高定位的准确性，用一种自适应的方法调整metrics的权重
  2 RW 提到了Microscope和Sieve
论文里居然还提到了SRE…hh
3 Solution 3A Framwork 针对不同的情景，选择的metric也不一样。UI相关的，一般更在意latency；计算相关的比如hadoop，更在意cpu负载。文章把微服务系统看成是一个黑盒，那么metric的权重这样的概念就出来了。
3B Metric latency适合短连接服务，但不适合长连接服务。
常见的metric：latency、throughput、CPU、MEM、disk、I/O，power。power = throughput / latency
Gradient相关重要的metric：
Gradient(t) = Mj,i(t) - Mji(t-1)
Gradient ratio(t) = Gradient(t) / Mj,i(t)
还有两个没列出来
3C Graph Construction 基于PC算法，依旧是一个DAG。额，这部分看得我一头雾水
3D Random Walk Diagnosis 一个最直观也是最常用的根因定位方法是计算某个服务的metric和Anomaly服务的metric的相似度。我看的其他论文里也大致是这个思想
同样这篇论文用皮尔逊相似度，不过添加了权重的部分。可以得到vi和vj的关系（相似度）
Transition（游走）：向前（遇到高相似度）、向内（前后都是低相似度，则停留在自身）、向后（遇到低相似度）
3E Weight Update P(M) Precision Function，计算定位结果的准确性。还有更新权重，都是一个公式带过。
3F Example 收集了2小时（7200s）的数据，每5s一次收集，对于每个metric都有1440个记录。</description>
    </item>
    
    <item>
      <title>hugo上传博客脚本</title>
      <link>https://zecoo.github.io/hugo/posts/blog/hugo%E4%B8%8A%E4%BC%A0%E5%8D%9A%E5%AE%A2%E8%84%9A%E6%9C%AC/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/blog/hugo%E4%B8%8A%E4%BC%A0%E5%8D%9A%E5%AE%A2%E8%84%9A%E6%9C%AC/</guid>
      <description>我很傻的，每次更新博客之后都要手动输入
hugo -D git add . git commit -m &amp;quot;xxx&amp;quot; git push origin master  又不想下载git客户端一键push，写个脚本咯
#!/bin/bash hugo -D git add . echo &amp;quot;input commit info:&amp;quot; read -t 5 commit_info commit_info=${commit_info:-&amp;quot;update blog&amp;quot;} git commit -m &amp;quot;$commit_info&amp;quot; git push origin master  read提供一个默认值“update blog”，这样既可以修改commit info，5s后忘记输入的话也不用担心。
记得最后把sh文件权限给足：chmod 777 update.sh
参考 https://www.cnblogs.com/lottu/p/3962921.html （shell接收键盘输入）
https://blog.csdn.net/u010339879/article/details/77938911 （read添加默认值）</description>
    </item>
    
    <item>
      <title>服务器命令行美化</title>
      <link>https://zecoo.github.io/hugo/posts/server/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BE%8E%E5%8C%96/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/server/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BE%8E%E5%8C%96/</guid>
      <description>export PS1=&amp;quot;\[\033[33m\]\u\[\033[0m\]@\[\033[36m\]k8s\[\033[0m\]:\[\033[32m\]\W \[\033[0m\]$ &amp;quot;  但是有个问题，输了命令命令行前缀是变好看了，但是一旦退出就没有效果了。要把这个设置写进文件里才行。具体是$HOME/.bashrc这个文件，这样就OK啦。
# .bashrc # User specific aliases and functions alias rm=&#39;rm -i&#39; alias cp=&#39;cp -i&#39; alias mv=&#39;mv -i&#39; # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi export PS1=&amp;quot;\[\033[33m\]\u\[\033[0m\]@\[\033[36m\]k8s\[\033[0m\]:\[\033[32m\]\W \[\033[0m\]$ &amp;quot;  vim也可以美化一下
# vim 显示行号 cat &amp;lt;&amp;lt;EOF &amp;gt; ~/.vimrc set nu EOF  参考 https://learnku.com/articles/29209 （ssh炫酷UI）
https://blog.csdn.net/yelangjueqi/article/details/45556657 （修改.bashrc文件）</description>
    </item>
    
    <item>
      <title>hugo tutorial</title>
      <link>https://zecoo.github.io/hugo/posts/blog/hugo-tutorial/</link>
      <pubDate>Sun, 17 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/blog/hugo-tutorial/</guid>
      <description>hugo new theme zik-theme  可以创建一个新的主题。自己的主题就是从这里开始。
然后看看hugo官网对这些baseof.html、index.html里面语法的介绍吧
Variable和Function都是用两个大括号括起来{{ }}
{{ partial &amp;quot;header.html&amp;quot; . }}  这会添加layouts/partials/header.html 这个文件到目标文件。
访问预定义的变量（感觉就是config.yaml文件里定义的变量）用dot，访问和定义普通变量用$
&amp;lt;title&amp;gt;{{ .Title }}&amp;lt;/title&amp;gt; {{ $address := &amp;quot;123 Main St.&amp;quot; }} {{ $address }}  if-else，记住最后要有一个end
{{ if (isset .Params &amp;quot;description&amp;quot;) }} {{ index .Params &amp;quot;description&amp;quot; }} {{ else }} {{ .Summary }} {{ end }}  布局上需要注意的：&amp;lt;div&amp;gt; {{ .Title }} &amp;lt;/div&amp;gt;会输出：
&amp;lt;div&amp;gt; Hello, World! &amp;lt;/div&amp;gt;  而&amp;lt;div&amp;gt; {{- .Title -}} &amp;lt;/div&amp;gt;会输出：
&amp;lt;div&amp;gt;Hello, World!</description>
    </item>
    
    <item>
      <title>Kubeadm init node not found</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/kubeadm-init-node-not-found/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/kubeadm-init-node-not-found/</guid>
      <description>新坑哦～
5天都没有解决的新坑哦～
环境：  华为云学生机2c4g 鲲鹏通用计算增强型 | kc1.large.2 | 2vCPUs | 4GB  错误 kubeadm init 后卡在：
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;. This can take up to 4m0s [kubelet-check] Initial timeout of 40s passed.  然后按照提示查看kubelet的日志，显示“node xxx not found”
node &amp;quot;ecs-kc1-large-2-linux-20200511105949&amp;quot; not found Container &amp;quot;408a5e9f9958dd3919cecf4a944a25ce30582bc638d657fc065fec8c56579f2a&amp;quot; not found in pod&#39;s containers k8s.io/kubernetes/pkg/kubelet/kubelet.go:453: Failed to list *v1.Node: Get https://192.168.0.214:6443/api/v1/nodes?fieldSelector=metadata.name%3Decs-kc1-large-2-linux-20200511105949&amp;amp;limit=500&amp;amp;resourceVersion=0: dial tcp 192.</description>
    </item>
    
    <item>
      <title>Hugo添加代码高亮</title>
      <link>https://zecoo.github.io/hugo/posts/blog/hugo-code-highlight/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/blog/hugo-code-highlight/</guid>
      <description>方法：用hightlight.js做高亮。
针对不同的Hugo主题，应该有不同的思路。但是基本思路还是：
 head里添加css body中添加两个“script“元素第一个是js文件，第二个是loadjs  我用的是Hugo的contrast主题，打开文件夹theme - layout，找到博文的base.html，打开在里面添加基本思路中的文件。我仿照代码里本来有的目录，简单修改一下就可以了。（第二行是我添加的highlight css文件）
&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;{{ .Site.BaseURL }}css/index.css&amp;quot;&amp;gt; &amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;{{ .Site.BaseURL }}css/github.css&amp;quot;&amp;gt;  css的选择可以到GitHub上hightlight.js的src/style下面找。
js文件，用官网上的cdn就可以。或者直接下载下来。
参考 https://orianna-zzo.github.io/sci-tech/2018-01/blog养成记3-hugo的语法高亮配置/#使用highlight-shortcode进行高亮</description>
    </item>
    
    <item>
      <title>Metric to Graph思路及实践</title>
      <link>https://zecoo.github.io/hugo/posts/metrics/metric-graph%E6%80%9D%E8%B7%AF%E5%8F%8A%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 08 May 2020 00:17:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/metrics/metric-graph%E6%80%9D%E8%B7%AF%E5%8F%8A%E5%AE%9E%E8%B7%B5/</guid>
      <description>整体思路 01 查看Prom的metric： 写好PromQL获得自己想要的metric，这时候只是文本的形式。而且又臭又长。
&amp;quot;metric&amp;quot;: { &amp;quot;__name__&amp;quot;: &amp;quot;istio_requests_total&amp;quot;, &amp;quot;connection_security_policy&amp;quot;: &amp;quot;unknown&amp;quot;, &amp;quot;destination_app&amp;quot;: &amp;quot;productpage&amp;quot;, &amp;quot;destination_canonical_revision&amp;quot;: &amp;quot;v1&amp;quot;, &amp;quot;destination_canonical_service&amp;quot;: &amp;quot;productpage&amp;quot;, &amp;quot;destination_principal&amp;quot;: &amp;quot;spiffe://cluster.local/ns/default/sa/bookinfo-productpage&amp;quot;, &amp;quot;destination_service&amp;quot;: &amp;quot;productpage.default.svc.cluster.local&amp;quot;, &amp;quot;destination_service_name&amp;quot;: &amp;quot;productpage&amp;quot;, &amp;quot;destination_service_namespace&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;destination_version&amp;quot;: &amp;quot;v1&amp;quot;, &amp;quot;destination_workload&amp;quot;: &amp;quot;productpage-v1&amp;quot;, &amp;quot;destination_workload_namespace&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;instance&amp;quot;: &amp;quot;10.244.0.61:15090&amp;quot;, &amp;quot;job&amp;quot;: &amp;quot;envoy-stats&amp;quot;, &amp;quot;namespace&amp;quot;: &amp;quot;istio-system&amp;quot;, &amp;quot;pod_name&amp;quot;: &amp;quot;istio-ingressgateway-6489d9556d-ws6cg&amp;quot;, &amp;quot;reporter&amp;quot;: &amp;quot;source&amp;quot;, &amp;quot;request_protocol&amp;quot;: &amp;quot;http&amp;quot;, &amp;quot;response_code&amp;quot;: &amp;quot;200&amp;quot;, &amp;quot;response_flags&amp;quot;: &amp;quot;-&amp;quot;, &amp;quot;source_app&amp;quot;: &amp;quot;istio-ingressgateway&amp;quot;, &amp;quot;source_canonical_revision&amp;quot;: &amp;quot;1.5&amp;quot;, &amp;quot;source_canonical_service&amp;quot;: &amp;quot;istio-ingressgateway&amp;quot;, &amp;quot;source_principal&amp;quot;: &amp;quot;spiffe://cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account&amp;quot;, &amp;quot;source_version&amp;quot;: &amp;quot;unknown&amp;quot;, &amp;quot;source_workload&amp;quot;: &amp;quot;istio-ingressgateway&amp;quot;, &amp;quot;source_workload_namespace&amp;quot;: &amp;quot;istio-system&amp;quot; }, &amp;quot;value&amp;quot;: [ 1588918429.726, &amp;quot;5148&amp;quot; ] }  02 提取metric 用代码或者在浏览器中用Prom提供的HTTP API访问提取metrics。请不要用curl，这个坑在另一个博客里已经提到了。</description>
    </item>
    
    <item>
      <title>jq in terminal for json</title>
      <link>https://zecoo.github.io/hugo/posts/server/jq-in-terminal-for-json/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/server/jq-in-terminal-for-json/</guid>
      <description>Prom返回的json格式没有reindent，看起来很费眼睛。
{&amp;quot;metric&amp;quot;:{&amp;quot;__name__&amp;quot;:&amp;quot;istio_requests_total&amp;quot;,&amp;quot;destination_app&amp;quot;:&amp;quot;productpage&amp;quot;,&amp;quot;destination_service&amp;quot;:&amp;quot;productpage&amp;quot;,&amp;quot;value&amp;quot;:[1588929523.247,&amp;quot;10523&amp;quot;]}]}}  在命令行，想让其用缩进好的json展示出来，就要用到jq。
curl http://test.json | jq  只需要在后面加上jq，就可以看到漂亮的json格式数据
&amp;quot;metric&amp;quot;: { &amp;quot;__name__&amp;quot;: &amp;quot;istio_requests_total&amp;quot;, &amp;quot;connection_security_policy&amp;quot;: &amp;quot;unknown&amp;quot;, &amp;quot;destination_app&amp;quot;: &amp;quot;productpage&amp;quot;, &amp;quot;destination_canonical_revision&amp;quot;: &amp;quot;v1&amp;quot;, &amp;quot;destination_canonical_service&amp;quot;: &amp;quot;productpage&amp;quot;, &amp;quot;destination_principal&amp;quot;: &amp;quot;spiffe://cluster.local/ns/default/sa/bookinfo-productpage&amp;quot;, &amp;quot;destination_service&amp;quot;: &amp;quot;productpage.default.svc.cluster.local&amp;quot;, &amp;quot;destination_service_name&amp;quot;: &amp;quot;productpage&amp;quot;, &amp;quot;destination_service_namespace&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;destination_version&amp;quot;: &amp;quot;v1&amp;quot;, &amp;quot;destination_workload&amp;quot;: &amp;quot;productpage-v1&amp;quot;, &amp;quot;destination_workload_namespace&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;instance&amp;quot;: &amp;quot;10.244.0.61:15090&amp;quot;, &amp;quot;job&amp;quot;: &amp;quot;envoy-stats&amp;quot;, &amp;quot;namespace&amp;quot;: &amp;quot;istio-system&amp;quot;, &amp;quot;pod_name&amp;quot;: &amp;quot;istio-ingressgateway-6489d9556d-ws6cg&amp;quot;, &amp;quot;reporter&amp;quot;: &amp;quot;source&amp;quot;, &amp;quot;request_protocol&amp;quot;: &amp;quot;http&amp;quot;, &amp;quot;response_code&amp;quot;: &amp;quot;200&amp;quot;, &amp;quot;response_flags&amp;quot;: &amp;quot;-&amp;quot;, &amp;quot;source_app&amp;quot;: &amp;quot;istio-ingressgateway&amp;quot;, &amp;quot;source_canonical_revision&amp;quot;: &amp;quot;1.5&amp;quot;, &amp;quot;source_canonical_service&amp;quot;: &amp;quot;istio-ingressgateway&amp;quot;, &amp;quot;source_principal&amp;quot;: &amp;quot;spiffe://cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account&amp;quot;, &amp;quot;source_version&amp;quot;: &amp;quot;unknown&amp;quot;, &amp;quot;source_workload&amp;quot;: &amp;quot;istio-ingressgateway&amp;quot;, &amp;quot;source_workload_namespace&amp;quot;: &amp;quot;istio-system&amp;quot; }, &amp;quot;value&amp;quot;: [ 1588918429.</description>
    </item>
    
    <item>
      <title>PromQL query in http API</title>
      <link>https://zecoo.github.io/hugo/posts/metrics/promql-query-in-http-api/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/metrics/promql-query-in-http-api/</guid>
      <description>Prom官网给出http API例如获取2015年7月1号某天的数据这样写：（我获得了istio_requests_total的所有metric）
curl &#39;http://localhost:9090/api/v1/query?query=istio_requests_total&amp;amp;time=2015-07-01T20:10:51.781Z&#39;  我想用PromQL，类似Prom的UI针对repose_code对query进行过滤
query?istio_requsets_total{response_code=200}  按照普通的思路我试着这样修改curl地址如下：
curl &#39;http://localhost:9090/api/v1/query?query=istio_requsets_total{response_code=200}&amp;amp;time=2020-05-07T20:10:51.781Z&#39;  失败。花了很长时间找资料，找不到。
最后用浏览器试一下，在http://localhost:9090/api/v1/query?query=之后把PromQL直接粘贴在后面就可以访问到。浏览器这边帮忙做了处理，最后的地址形式是这样的；
http://121.37.159.247:30040/api/v1/query?query=istio_requests_total{response_code=%22200%22}  把引号&amp;quot;处理成了%22。
参考 https://prometheus.io/docs/prometheus/latest/querying/api/ （官方http API用法）</description>
    </item>
    
    <item>
      <title>PromQL理解</title>
      <link>https://zecoo.github.io/hugo/posts/metrics/promql%E7%90%86%E8%A7%A3/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/metrics/promql%E7%90%86%E8%A7%A3/</guid>
      <description>期待数据 10min内的请求数（sum）
istio_requests_total{destination_service_name=&amp;quot;productpage&amp;quot;}  10min内的请求数增长率（rate）
rate(istio_requests_total{destination_app=&amp;quot;productpage&amp;quot;}[10m])  10min内的响应时间P90（quantile）
histogram_quantile(0.90, sum(rate(istio_request_duration_milliseconds_bucket{destination_app=&amp;quot;productpage&amp;quot;}[10m])) by(le))  10min内的响应时间增长率（rate）
rate(istio_request_duration_milliseconds_bucket{destination_app=&amp;quot;productpage&amp;quot;}[10m])  参考 https://www.zhihu.com/question/380615839 （Prom时区UTC没法改）</description>
    </item>
    
    <item>
      <title>Meta Metrics</title>
      <link>https://zecoo.github.io/hugo/posts/metrics/meta-metrics/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/metrics/meta-metrics/</guid>
      <description>siege一分钟压测最后给出的统计数据：
Lifting the server siege... Transactions:	439 hits Availability:	51.83 % Elapsed time:	59.33 secs Data transferred:	8.47 MB Response time:	9.88 secs Transaction rate:	7.40 trans/sec Throughput:	0.14 MB/sec Concurrency:	73.10 Successful transactions: 439 Failed transactions:	408 Longest transaction:	56.69 Shortest transaction:	0.13  istio Envoy的access log：
【START_TIME】[2020-05-06T09:32:24.488Z] 【METHOD】&amp;quot;GET 【PATH】/flasgger_static/swagger-ui-bundle.js 【PROTOCOL】HTTP/1.1&amp;quot; 【REPONSE CODE】200 - &amp;quot;-&amp;quot; &amp;quot;-&amp;quot; 0 1048149 261 225 【FORWARD_FOR】&amp;quot;-&amp;quot; 【AGENT】&amp;quot;Mozilla/5.0 (pc-x86_64-linux-gnu) Siege/4.0.5&amp;quot; 【REQUEST_ID】&amp;quot;51b45953-9ede-9390-b8b5-162247165a5b&amp;quot; 【AUTHORITY】&amp;quot;10.108.208.232:8000&amp;quot; 【HOST】&amp;quot;127.0.0.1:80&amp;quot; 【SERVICE】inbound|8000|http|httpbin.default.svc.cluster.local 【CLUSTER_IP】127.</description>
    </item>
    
    <item>
      <title>istio envoy log type</title>
      <link>https://zecoo.github.io/hugo/posts/istio/istio-envoy-log-type/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/istio/istio-envoy-log-type/</guid>
      <description>Envoy log type 【START_TIME】[2020-05-06T09:32:24.488Z] 【METHOD】&amp;quot;GET 【PATH】/flasgger_static/swagger-ui-bundle.js 【PROTOCOL】HTTP/1.1&amp;quot; 【REPONSE CODE】200 - &amp;quot;-&amp;quot; &amp;quot;-&amp;quot; 0 1048149 261 225 【FORWARD_FOR】&amp;quot;-&amp;quot; 【AGENT】&amp;quot;Mozilla/5.0 (pc-x86_64-linux-gnu) Siege/4.0.5&amp;quot; 【REQUEST_ID】&amp;quot;51b45953-9ede-9390-b8b5-162247165a5b&amp;quot; 【AUTHORITY】&amp;quot;10.108.208.232:8000&amp;quot; 【HOST】&amp;quot;127.0.0.1:80&amp;quot; inbound|8000|http|httpbin.default.svc.cluster.local 127.0.0.1:43000 10.244.0.67:80 10.244.0.1:10504 - default  获取相应时间数据 特别得，我想知道响应时间，但是好像没有具体列出来。不过每个envoy log都有4个数字特别可疑：
0 135 1 1 (/status/418) 0 9593 73 73 (http/1.1) 0 1428809 1 1 (swagger-ui.bundle.js) 0 85578 1 0 (jquery.min.js) 0 0 118 - (DC ResponseCode:0) 0 1048149 261 225 (swagger-ui.bundle.js)  那么这4串数字分别代表什么呢？根据Envoy官方给出的对应关系，由于HTTP_FLAGS一般都是比较特别的，而我得到的都是&amp;rdquo;-&amp;ldquo;，可以得到对应关系：
[1]BYTES_RECEIVED [2]BYTES_SENT [3]DURATION [4]ENVOY-UPSTREAM-SERVICE-TIME  于是响应时间duration其实就可以拿到了。</description>
    </item>
    
    <item>
      <title>scss tutorial</title>
      <link>https://zecoo.github.io/hugo/posts/static-web/scss-tutorial/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/static-web/scss-tutorial/</guid>
      <description>SCSS：Sassy CSS
SASS比SCSS更简洁啊，感觉更像现代编程语言，跟yaml一样。
我咋还在scss的环境上踩到坑了呢？
先是给我报错
bad interpreter: /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/bin/ruby: no such file or directory  一查是sass环境没装上……我以为mac自带ruby不用管呢
sudo gem install -n /usr/local/bin sass --pre  安装之。然后发现ruby的源用不了，原来是 https://gems.ruby-china.org 改成了 https://gems.ruby-china.com ，害。
编译css的项目目录也需要更改，默认是编译到scss相同的目录。
{ &amp;quot;cmd&amp;quot;: [ &amp;quot;sass&amp;quot;, &amp;quot;--update&amp;quot;, &amp;quot;$file:${file_path}/../css/${file_base_name}.css&amp;quot;, &amp;quot;--stop-on-error&amp;quot;, &amp;quot;--no-cache&amp;quot;], &amp;quot;osx&amp;quot;: { &amp;quot;path&amp;quot;: &amp;quot;/usr/local/bin:$PATH&amp;quot; } }  最后sublime再装一个插件&amp;rdquo;sublimeBuildOnSave&amp;rdquo;自动编译sass，不要每次都cmd+B一下。
参考 https://www.jianshu.com/p/f8cbe91498dc （ruby china换源了）
https://www.sass.hk/install/ （ruby 安装sass）
https://blog.logrocket.com/getting-started-with-bootstrapvue-2d8bf907ef11/ （bootVue blog）
https://bootstrap-vue.org/docs （bootVue官网）</description>
    </item>
    
    <item>
      <title>k8s HPA尝试</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/k8s-hpa%E5%B0%9D%E8%AF%95/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/k8s-hpa%E5%B0%9D%E8%AF%95/</guid>
      <description>先提一个题外话：如何销毁已经创建的部署？答：
有kubectl create -f ./metrics-server就有kubectl delete -f ./metrics-server
按照主要参考，大部分都可以实现。但是有几个坑需要注意
 autoscaling的版本分为v1beta1、v2beta1、v2beta2。用法不同 deployment: extension/v1beta1这样的用法我改为apps/v1beta1创建HPA才能成功  HPA的重点是hpa.yaml里面的cpu和mem的指定。
Prometheus + HPA的重点是如何将Prom的数据改为metrics server可以使用的数据。这里的方法应该是config-map中构建的一系列rule。先拿来用，暂时不去深究。
参考 https://blog.csdn.net/yevvzi/article/details/79561150 （本文主要参考）
https://blog.csdn.net/xktxoo/article/details/87909432 （jq介绍）
https://cloud.tencent.com/developer/article/1394657 （selector问题）
https://q.cnblogs.com/q/125354/ （target问题）
https://blog.51cto.com/13740724/2368066 （新版本该这么用）
https://www.cnblogs.com/yunqishequ/p/10006896.html （不同版本autoscaling）
https://stackoverflow.com/questions/43163625/when-i-use-deployment-in-kubernetes-whats-the-differences-between-apps-v1beta1 （deployment version）</description>
    </item>
    
    <item>
      <title>Prometheus Metric形式</title>
      <link>https://zecoo.github.io/hugo/posts/metrics/prom-metric%E5%BD%A2%E5%BC%8F/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/metrics/prom-metric%E5%BD%A2%E5%BC%8F/</guid>
      <description>Prom的四种基本metric类型  counter：从0开始计数的，比如http_req_total gauge：有浮动的指标，比如cpu、mem histogram：统计数据，比如P90 summary：和histogram类似  几个示例 P90  The φ-quantile is the observation value that ranks at number φ*N among the N observations. Examples for φ-quantiles: The 0.5-quantile is known as the median. The 0.95-quantile is the 95th percentile.
 分位点的概念。官方示例：10分钟内请求持续时间的90%，以PromQL的形式给出：
histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[10m]))  以下数据是通过 curl http://121.37.159.247:30040/metrics 获取的，截取部分。
# HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of WAL fsync. # TYPE prometheus_tsdb_wal_fsync_duration_seconds summary prometheus_tsdb_wal_fsync_duration_seconds{quantile=&amp;quot;0.5&amp;quot;} 0.012352463 prometheus_tsdb_wal_fsync_duration_seconds{quantile=&amp;quot;0.9&amp;quot;} 0.014458005 prometheus_tsdb_wal_fsync_duration_seconds{quantile=&amp;quot;0.99&amp;quot;} 0.017316173 prometheus_tsdb_wal_fsync_duration_seconds_sum 2.888716127000002 prometheus_tsdb_wal_fsync_duration_seconds_count 216  “从上面的样本中可以得知当前Prometheus Server进行wal_fsync操作的总次数为216次，耗时2.</description>
    </item>
    
    <item>
      <title>K8s &#43; Istio 概念</title>
      <link>https://zecoo.github.io/hugo/posts/istio/k8s-&#43;-istio-%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Thu, 30 Apr 2020 10:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/istio/k8s-&#43;-istio-%E6%A6%82%E5%BF%B5/</guid>
      <description>环境都搭好了，不知道里面的原理那可不行。
我也不会系统写，想到哪里就写到哪里吧。
istio是如何做到无侵入就能控制流量转发？ Sidecar还有Envoy是这里的核心。
这个图就很好得说明了sidecar中流量的走向。这部分在华为的书《云原声服务网格istio》中关于sidecar的介绍写得很清楚。也就是说Envoy通过iptables拦截了进来的流量，然后强迫流量走自己的通道，相当于一个收保护费的。
那么iptables为什么这么屌，能把流量给拦截下来？其实iptables改名叫netfilter更形象一些。先不深究iptables是如何做转发的，形象理解iptables为何这么屌，其实是它作为一个内核设置的功能，可以把网卡接受到的流量先通过自己过滤，然后再发送给web应用。
那么也就是，我从Safari发起对http://serverip:port/productpage访问，首先流量通过我的网卡，经过计算机网络传到server的网卡，然后server的网卡把这条流量先交给iptables过滤一下，然后再发给productpage代表的微服务。
iptables我好像把它关了，但是我的istio依然能够工作？这又是为什么呢…
k8s如何调度微服务节点的 搞清楚这样几个概念：pod、deployment、service、node
 一个pod上跑k个容器，这k个容器组成一个app（微服务） deployment，其实叫replica controller更合适。顾名思义，就是扩缩pod service就是app对外的一个访问入口。一个svc中可能有n个replica node就是部署service的节点  那么到这里我有一个小问题，有如果有n个replica，那么流量进来了会被分配到哪个pod里呢？
kubelet是什么 kubelet是node的proxy。
k8s的DNS是什么 给每个svc可用地址。
（以上两个百度结果都不太好，姑且这么理解吧）
参考 http://www.zsythink.net/archives/1199/ （讲iptables的好文）</description>
    </item>
    
    <item>
      <title>Istio 可视化插件概览</title>
      <link>https://zecoo.github.io/hugo/posts/istio/istio-%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8F%92%E4%BB%B6%E6%A6%82%E8%A7%88/</link>
      <pubDate>Thu, 30 Apr 2020 10:35:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/istio/istio-%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8F%92%E4%BB%B6%E6%A6%82%E8%A7%88/</guid>
      <description>Prometheus 基本的metrics监测插件。
通过query查询不同的信息，例如以下信息就是istio_requests_total这条query查询到的n条数据中的一条。（不全，删除了部分我不关注的信息）
istio_requests_total{destination_app=&amp;quot;productpage&amp;quot;,destination_principal=&amp;quot;spiffe://cluster.local/ns/default/sa/bookinfo-productpage&amp;quot;,destination_service=&amp;quot;productpage.default.svc.cluster.local&amp;quot;,destination_service_name=&amp;quot;productpage&amp;quot;,destination_service_namespace=&amp;quot;default&amp;quot;,destination_version=&amp;quot;v1&amp;quot;,destination_workload=&amp;quot;productpage-v1&amp;quot;,instance=&amp;quot;10.244.0.24:15090&amp;quot;,job=&amp;quot;envoy-stats&amp;quot;,namespace=&amp;quot;istio-system&amp;quot;,pod_name=&amp;quot;istio-ingressgateway-6489d9556d-bc48z&amp;quot;,response_code=&amp;quot;503&amp;quot;,source_workload=&amp;quot;istio-ingressgateway&amp;quot;,source_workload_namespace=&amp;quot;istio-system&amp;quot;}  Grafana Metrics可视化插件。
Request Volume代表什么？
Request Duration中的P50、P90分别代表什么？
Jaegar 主要显示调用了哪些微服务，调用顺序是什么样的，响应时间是多少。
Kiali 链路追踪可视化插件。可以看出有几个微服务，调用关系是什么样的。
里面也有P50、P90。说明这个很关键啊。
P90=100ms，就是说90%的请求其响应时间在100ms以内，剩余10%的响应时间大于100ms。
Siege 压测工具。来看看压测结果
$ siege -d 10 -c 200 -t 2 http://121.37.159.247:32753/productpage Lifting the server siege... Transactions:	519 hits Availability:	99.24 % Elapsed time:	119.34 secs Data transferred:	20.14 MB Response time:	9.01 secs Transaction rate:	4.35 trans/sec Throughput:	0.17 MB/sec Concurrency:	39.17 Successful transactions: 519 Failed transactions:	4 Longest transaction:	110.01 Shortest transaction:	0.</description>
    </item>
    
    <item>
      <title>Istio 安装回顾</title>
      <link>https://zecoo.github.io/hugo/posts/istio/istio-%E5%AE%89%E8%A3%85%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Wed, 29 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/istio/istio-%E5%AE%89%E8%A3%85%E5%9B%9E%E9%A1%BE/</guid>
      <description>如果是Microk8s安装，很简单就一步：
microk8s.enable istio  好像pull istio镜像的过程特别漫长。由于用的是力的2g服务器，到这里内存爆炸，用不了了。
然后转战华为云15天4g服务器试用。
用Kubeadm安装k8s，过程呢，在另一篇博客中。
这里主要回顾Kubeadm安装istio以及各种可视化插件的过程。
全程请把精力集中在istio的官网上。每个教程都很详细。
下载tar包，然后解压得到istio-15.2目录。这个目录里包含需要部署的yaml文件以及bookinfo的实例。
我居然还遇到了docker.io不能pull镜像的问题。又要换一个源……
然后按照istio官方的教程去安装就OK了。
重点呢，是各种可视化插件的部署。如果istio部署顺利的话，各种插件的svc已经启动了，可以get svc查看一下。但是到目前为止还是只能在集群内访问。访问的入口是istio-ingressgateway。然后按照istio官方给出的远程访问方式去部署就好了。这里唯一一个和官方给出的教程不同的地方是，以Prometheus为例，官方给出的访问地址是：
 Prometheus: http://&amp;lt;IP ADDRESS OF CLUSTER INGRESS&amp;gt;:15030/  这里的ingressip要改为
[服务器地址] + [svc istioingressgateway对于15030暴露的端口]
然后就可以用上面的地址访问到Prometheus了。
当然我还搜到了另外一种方式访问，把Prometheus用另一个svc包裹起来，相当于多了一个nodeport svc的中介。输入这个命令即可：
kubectl expose service prometheus --type=NodePort \ --name=prometheus-svc --namespace istio-system  然后就会多出来一个名为prometheus-svc的nodeport形式的服务。调用这个服务暴露出来的地址就可以访问Prometheus，只是我觉得这个方法可能不太安全，就没有用。
参考 https://www.jianshu.com/p/b72c1e06b140 （安装指南）
https://www.cnblogs.com/assion/p/11326088.html （修改istiogateway的LB为nodeport）
https://www.jianshu.com/p/b72c1e06b140 （用hello-node做示例）
https://www.cnblogs.com/davidwang456/articles/9311470.html （SLA和SLO的关系）
https://www.jianshu.com/p/fd90d4914505 （istio的良好实践）
https://www.jianshu.com/p/bed143a1c886 （估计也是个研究生大神，给王老师演示这个就可以了）
https://www.cnblogs.com/CCE-SWR/p/10286404.html （也是演示之用）
https://www.ibm.com/support/knowledgecenter/en/SSBS6K_2.1.0.3/manage_cluster/istio.html （另一种暴露Prometheus的方式）
https://www.jianshu.com/p/9031fdf61115 （docker.io加速）
https://istio.io/zh/docs/tasks/observability/gateways/ (官方暴露prom服务)</description>
    </item>
    
    <item>
      <title>Kubeadm 安装记录</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/kubeadm-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 28 Apr 2020 16:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/kubeadm-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</guid>
      <description>装好的那一瞬间，我感动得要哭了。我现在也算半个k8s运维小能手了吧。
安装K8s有这几种方法
 minikube mircok8s kubeadm  这三种方法我都用过。minikube在win上以虚拟机的形式运行，挺麻烦的讲道理。microk8s是最友好的方式，解决一个拉镜像的问题，也就不成问题了。kubeadm应该是最麻烦的了。
回归正题，记录整个安装以及填坑的过程。
首先docker要安装上。
然后，kubelet、kubeadm、kubectl、kubernetes-cni一套安装下来。
我现在才看到参考1中的一句话：
# 指定版本否则都会默认安装库中最新版本，会因为彼此依赖的版本不同安装失败 $ yum install -y kubelet-1.13.1 kubeadm-1.13.1 kubectl-1.13.1 kubernetes-cni-0.6.0 # 设置开机启动并启动kubelet $ systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet  看到第一句话了吗？给我大声读几遍！！我就是因为这个，吃了多少亏，搜索多少资料😭。请一定保证你的kubelet、kubeadm、kubectl的版本相同。
第二步，kubeadm config images list列出所有需要的image，因为国内网络问题嘛，一样的。然后用以下bash脚本安装好，docke images检查一下。
for i in `kubeadm config images list`; do imageName=${i#k8s.gcr.io/} docker pull registry.aliyuncs.com/google_containers/$imageName docker tag registry.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName docker rmi registry.aliyuncs.com/google_containers/$imageName done;  第三步，kubeadm init --pod-network-cidr=10.244.0.0/16初始化kubeadm。这一步最重要的是/etc/kubernetes/admin.conf这个文件。还有后面那个参数，如果不加上，就会遇到新的坑哦～
init结束之后，不要忘了提示的三行命令，不然会报错：
Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of &amp;quot;crypto/rsa: verification error&amp;quot; while trying to verify candidate authority certificate &amp;quot;kubernetes&amp;quot;)  mkdir -p $HOME/.</description>
    </item>
    
    <item>
      <title>Kubectl client 和 server version 差距错误</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/kubectl-client-%E5%92%8C-server-version-%E5%B7%AE%E8%B7%9Dbug/</link>
      <pubDate>Tue, 28 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/kubectl-client-%E5%92%8C-server-version-%E5%B7%AE%E8%B7%9Dbug/</guid>
      <description>每天捣鼓k8s就是各种填坑。不过在查问题解决办法的时候有个人说
 遇到坑不要怕，百度谷歌就是了。填完了坑，再踩两脚，以后走起来就平了。
 说得真好。爆炸的心态慢慢也就平复了。
回归正题，坑长这个样子：
kubectl -f apply any.yaml  都会报错：
Error from server (NotFound): the server could not find the requested resource  一开始我以为是apiserver的问题，但是apiserver是正常运行的。搜索了很长时间，还是在yandex上搜索到可能是Kubectl cli和server的版本差距过大造成的问题。
看一下我的两个版本：kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.3&amp;quot;, GitCommit:&amp;quot;5fa2db2bd46ac79e5e00a4e6ed24191080aa463b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-01-18T21:12:46Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;} Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;16&amp;quot;, GitVersion:&amp;quot;v1.17.5&amp;quot;, GitCommit:&amp;quot;72c30166b2105cd7d3350f2c28a219e6abcd79eb&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2020-01-18T23:23:21Z&amp;quot;, GoVersion:&amp;quot;go1.13.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}  可以看到cli的版本是v1.9.3，而server的版本是1.17.5。差的太多了。
继续搜索如何升级kubectl cli之，百度就别想能找到答案了。在k8s官网找到了安装kubectl的方法，重新安装了一下，kubectl cli的版本就升级到最新v1.18.5了。
这下再试一下
kubectl apply -f anyfile.yaml  终于可以运行yaml文件了。
参考 https://kubernetes.io/docs/tasks/tools/install-kubectl/#before-you-begin （升级kubectl cli）
https://devops.stackexchange.com/questions/2956/how-do-i-get-kubernetes-to-work-when-i-get-an-error-the-server-could-not-find-t （坑出现的原因1）</description>
    </item>
    
    <item>
      <title>IFE task0002_5 回顾</title>
      <link>https://zecoo.github.io/hugo/posts/static-web/ife-task0002_5-%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Thu, 23 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/static-web/ife-task0002_5-%E5%9B%9E%E9%A1%BE/</guid>
      <description>做这个任务的时候我一度想要放弃。因为基础不牢，觉得这东西对我来说有点难啊。结果磕磕绊绊借鉴DIYgod的网页做出来之后，发现这东西真tm是基础。
我也百度了一下，发现写task0002_5的博客少之又少，说明ife的任务2到这里，基本上已经没有很多人在做了。
瞎总结 首先要了解事件是个什么东西。在这个任务里面，要监听的是
 滑块被拖动时的位置 dragStart(e) 滑块处于拖动状态 dragging(e) 滑块最后放置的位置 drop(e)  而在js里，有专门针对拖动的监听事件*dragStart*和*drop*方法。
让滑块动起来 首先要给滑块设置draggable=true，然后就会神奇得发现滑块真的可以拖动了。留下一个残影在原来的位置。但是也会神奇得发现鼠标一松开还是要打回原形。
先做第一个动画，拖动一个滑块A的时候，首先A要在wrap中消失。可以用css添加一个class dragging，设置display=none。监听滑块处在拖动的状态时，就是不可见的。而一旦落了脚，要移除这个class。重新回到可见状态。
第一个动画做完，可以发现，拖动A，A下面的滑块会自动补上A的位置。松开鼠标依旧打回原形。
单个容器拖动效果 然后尝试做单个容器内滑块的拖动效果。第二个动画该考虑把要移动的滑块A插到合适的地方。这里面有这样几步
 获取当前滑块A的中心相对容器的坐标。得出插入第k格 将A插入指定位置 A下面的滑块均向下移动一格  我在这里偷了个懒，仅根据drop事件当前的鼠标位置来判断插入哪一格。具体细节先不追究，毕竟还要抓紧学vue的知识。2、3步也比较简单，让每个滑块position=absolute，然后设置一个top值，就可以控制滑块的移动了。
多容器拖动效果 最后将单容器拓展到双容器甚至多容器，其实仅比单容器多了一步，就是根据滑块drop的中心位置判断落在哪个容器。
踩坑记 我写回顾主要是想记一下自己踩的坑。
$.on(document.body, &#39;dragover&#39;, dragOver);  没错，全在这一行代码里了。
$.on是util.js里addEvent(element, event, listener)的封装。
 element，就是监听对象。我在做drop效果的时候，打死都出不来。随便一拖动，滑块就没了。最后定位到是element的问题，我打开html检查器，发现自己没有定义container的高度，结果就是整个body只有一丢丢高，并没有把容器包括进去。所以我拖动的滑块，其实在监听对象body之外。那肯定是没得效果咯。 event，这…我本来以为没啥实际意义的参数，又给我栽一大跟头，让我不好好看文档先学习用法。event要和listener方法名一致，并且全部小写。 dragOver别看就一行代码，e.preventDefault();，这是为了防止浏览器拖动结束没来得及drop就结束监听。不然又会遇到一拖动滑块就消失了的情况。  以上。
参考 https://www.runoob.com/jsref/event-ondrag.html （菜鸟onDrag事件）
https://www.jianshu.com/p/2dfb870e0b88 （本任务类型）</description>
    </item>
    
    <item>
      <title>Bayesian Optimization 直观理解</title>
      <link>https://zecoo.github.io/hugo/posts/math/bayesian-optimization/</link>
      <pubDate>Tue, 21 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/math/bayesian-optimization/</guid>
      <description>目标 最小(大)化一个没有具体表达式的函数。
举个例子 给定一个函数 $$ f(x,y) = -x^2 - (y-1)^2 +1 $$
BO通过几次迭代找到能让 f(x,y) 最小的x和y的值。
吐槽一下 中文的科普环境能不能再差一点？都尼玛是秀智商的。
一个简单的东西讲得巨鸡儿复杂，还觉得自己抖机灵挺可爱的。说得就是这篇博客。
幸好让我遇到了还算可以的另一篇博客。
当然都不及老外的blog。
我真的不是崇洋媚外。就是在讲一个事实。科学的范畴，中文优秀博客少得可怜。至少百度出来的是这样。</description>
    </item>
    
    <item>
      <title>K8S Proxy</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/k8s-proxy/</link>
      <pubDate>Tue, 21 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/k8s-proxy/</guid>
      <description>上一节讲到现在可以在vps上访问到hello-world了。
然而我想把访问操作放在我的电脑上。我没有想到NodePort这么容易就能做到了。修改一下service.yaml里面port的type，从ClusterIP改为NodePort就可以了。
到这里我已经很满足了，但是手痒痒想要看看dashboard的情况。首先嘛，得先把dashboard服务给启动起来对不对？不幸的是，在之前装microk8s的时候，我使用了这样一行命令添加了dns和dashboard这两个add-on
kubectl enable dns dashboard  结果就是，dashboard其实已经启动了，只是我一直使用的命令
kubectl get svc  只能显示namespace为default的service，就看不到dashboard也已经启动了。
如果想要查看所有的svc还是添加--all-namespaces选项。
ubuntu@VM-0-12-ubuntu:~$ sudo kubectl get svc --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE container-registry registry NodePort 10.152.183.11 &amp;lt;none&amp;gt; 5000:32000/TCP 13d default hello-node NodePort 10.152.183.14 &amp;lt;none&amp;gt; 8080:31908/TCP 4d4h default kubernetes ClusterIP 10.152.183.1 &amp;lt;none&amp;gt; 443/TCP 13d kube-system dashboard-metrics-scraper ClusterIP 10.152.183.247 &amp;lt;none&amp;gt; 8000/TCP 13d kube-system heapster ClusterIP 10.152.183.227 &amp;lt;none&amp;gt; 80/TCP 13d kube-system kube-dns ClusterIP 10.152.183.10 &amp;lt;none&amp;gt; 53/UDP,53/TCP,9153/TCP 13d kube-system kubernetes-dashboard NodePort 10.</description>
    </item>
    
    <item>
      <title>K8S hello-world 回顾</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/k8s-hello-world/</link>
      <pubDate>Fri, 17 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/k8s-hello-world/</guid>
      <description>没错这部分也花了我很长时间，而且把我心态还搞崩了。
k8s安装主要是镜像是国外私有库，pull下来比较麻烦。
而k8s第一个hello-world难在理解pod、deployment、service之间的关系，以及各种奇奇怪怪的端口映射。我想这是计算机网络基础没有打好埋的坑吧。
镜像&amp;amp;Pod 首先是创建pod，这里也需要把本地docker创建的image给注射到microk8s.ctr里面。我根据参考1给出的方法构建了hello-node:v1镜像。然后注入到k8s里面。
image创建成功之后，就可以构建pod了。用以下命令
kubectl run hello-node --image=hello-node:v1 --port=8080 --image-pull-policy=Never  创建了一个pod，可以用命令
kubectl get pods  查看pod的创建。如果创建不成功，可以具体查看pod的详细情况。
kubectl describe pod hello-node  创建Deployment pod创建成功了，考虑构建deployment，dep是pod的无状态体现。deployment可以控制pod的replica数量。创建方法我没有找到命令行的方式，k8s官网给出的也是推荐使用yaml构建。以下是deployment.yaml文件：
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2 kind: Deployment metadata: name: hello-node spec: selector: matchLabels: name: hello-node replicas: 1 # tells deployment to run 2 pods matching the template template: metadata: labels: name: hello-node spec: containers: - name: hello-node image: hello-node:v1 ports: - containerPort: 8080  有了yaml文件，然后用以下命令可以创建deployment</description>
    </item>
    
    <item>
      <title>ife 轮播图回顾</title>
      <link>https://zecoo.github.io/hugo/posts/static-web/ife-%E8%BD%AE%E6%92%AD%E5%9B%BE%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Wed, 15 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/static-web/ife-%E8%BD%AE%E6%92%AD%E5%9B%BE%E5%9B%9E%E9%A1%BE/</guid>
      <description>写在前面 做到ife task002_3，轮播图花了我最长的时间来写，甚至让我开始反思自己是不是真的…不适合当一个程序员。我要成了程序员，有种侮辱了这个群体的感jio。最后看了一下，虽然也就125行的代码，断断续续我大概做了一周。😓
html&amp;amp;CSS也遇到问题：  怎么把6张图片都塞到frame里面去不漏出来。简单一个overflow：hidden我就是想不到。 6个按钮小圆点怎么放到frame里面。其实还是position的问题，我总是自以为了解position，然而到了真正实践的时候就出问题。小圆点div相对于frame的position要absolute。 如何让图片有一个滑动的效果？我是看了DIYgod的代码之后，才知道要让图片float left，让图片div的宽度仅可能宽，让图片相对于左上角每次移动一部分距离，就能实现移动的效果了。  最要命的是JS部分 一开始我百度了一个轮播图的代码，是通过调整其他图片display：none，指定index的图片display：block。这样就简单实现了图片的切换。这样做也没有什么问题，但就是没有滑动的动画效果，看起来很low。
干脆继续参考DIYgod的代码。就有了上面提到的，让图片横向展开在页面中。每次切换让图片向左或向右移动一定的距离offset。也就是图片div的left增加或减少offset。如果移动一张图片距离，那么就是offset=img.width。
Next &amp;amp; Prev button 于是我先把next、prev点击切换的功能做出来，还算简单，主要注意的是next移动到第六张图片的时候，要跳回到第一张图片，要用if做个判断。prev移动到第一张照片的时候同理。
移动动画效果 到这里可以发现，到目前为止，功能做出来和display：none的那一版没有任何区别。因为移动在一瞬间就完成了，没有形成动画效果。
如果想要动画效果，要在一定时间time内逐步完成移动。做法是设置每个时间间隔interval移动一小段距离，那么每个时间间隔移动的距离就是offset / (time / interval)。然后设置一个setTimeout函数执行移动过程。
好，动手操作一下。然后就会惊奇的发现：操，我的轮播图怎么停不下来了？是因为setTimeout之后，每个时间间隔就会执行一次，不设置停止条件的话就会一直执行下去。那么停止条件是什么呢？图片移动了offset的距离，这个动画过程就应该结束。所以停止条件就是initialLeft + offset = newLeft的时候。
再来看看轮播图效果怎么样？next和prev按钮都可以使用了，而且也有了动画效果。小阶段目标完成，先给自己小小鼓励一下。
小圆点 接下来考虑实现小圆点和图片的index的同步。这中间也有一些trick，我随便想想发现悟不到就又看了Dg的代码。
首先考虑怎么做到让某个index的小圆点（下面用O表示）亮起来呢？Dg给出的方法是，给index的O添加一个class比如light，CSS中设置该class light的bgc=white，就相当于让index的O亮起来了，挺巧妙的。同时要注意，亮起来了，还要让他灭掉，也很简单，把所有O的light class都给remove掉。
好的，现在任意index的O都可以控制其亮或者不亮了。直接把这个方法封装成showBtn()。在next、prev的点击操作中，添加showBtn方法，就可以成功看到指定index的O亮起来了，和图片实现了同步。
小圆点这里还没完。通常在轮播图中点击某个位置的O，应该能跳转到该index的图片。这里Dg在html中给每个O设置了一个index=0~6属性，通过this.getAttribute()方法获取当前index。有了当前的index，和要移动到的index，相减乘以图片的width，就是要移动的offset。那么到这里这个功能也就实现了。
所以到最后的顺时针、逆时针播放就更简单了，setInterval()，每隔1000ms执行一次next或者prev，就OK了。但是要注意，如果先后点击playASC和playDESC，会发生鬼畜。解决方法是在这两个方法执行前先判断一下，如果setInterval的timer还在的话，就stop掉。这样鬼畜的问题也就解决了。
最后 别看我回顾就写了1.3k字，写代码花费的时间真的比我想象中的多多了。感觉那些程序员坐一下午能搞出各种各样的功能，我这……真的菜啊。</description>
    </item>
    
    <item>
      <title>Microk8s 国内安装总结</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/microk8s-installation-in-china/</link>
      <pubDate>Thu, 09 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/microk8s-installation-in-china/</guid>
      <description>Ubuntu18本身自带snap，可以在microk8s的官网找到安装方法。
注意k8s的运行条件只要满足以下
 Linux kernel在3.1以上，很多小的openZV的服务器，都是2.6的核儿 Memory要在2G或以上。  我在国外买的xs vps就emmm。再附自己检查kernel的过程
$ uname -r (check linux kernel) $ dpkg --print-architecture (check linux architecture amd64/arm64)  按照官网的方法，安装成功的话输入sudo kubectl version应该能看到client和server信息。
但是现在的microk8s还需要安装一些add-on，装这些add-on的时候就会有问题了。
sudo mircok8s enable dns dashboard
这里开启microk8s的dns和dashboard服务，但是尝试一下会发现dashboard并不能使用。如果server装了ss可以翻wall，应该不会有这个问题。如果没有ss，用这个命令检查一下namespace为kube-system的pod的情况。
sudo microk8s.kubectl get pods --all-namespaces
你会看到以下信息：
NAMESPACE NAME READY STATUS RESTARTS AGE container-registry registry-7cf58dcdcc-rlfdq 1/1 Running 1 18h default hello-node 0/1 ImagePullBackOff 0 16h kube-system coredns-588fd544bf-nmnnl 1/1 Creating 1 19h kube-system dashboard-metrics-scraper-db65b9c6f-46lrb 1/1 Creating 1 19h kube-system heapster-v1.</description>
    </item>
    
    <item>
      <title>SS on Ubuntu</title>
      <link>https://zecoo.github.io/hugo/posts/k8s/ss-on-ubuntu/</link>
      <pubDate>Thu, 09 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/k8s/ss-on-ubuntu/</guid>
      <description>弄起来挺快的，其实就三点
 安装ss。apt install就可以 配置ss。就一个json文件 启动ss。一行命令  参考： https://viencoding.com/article/90</description>
    </item>
    
    <item>
      <title>初试Nginx部署静态网页</title>
      <link>https://zecoo.github.io/hugo/posts/static-web/%E5%88%9D%E8%AF%95nginx%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5/</link>
      <pubDate>Thu, 09 Apr 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/static-web/%E5%88%9D%E8%AF%95nginx%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5/</guid>
      <description>在ife上也写了几个网页了，但是如果一直用github-pages的话，感觉有点麻烦，自己有一个服务器干嘛不直接用呢？
安装Nginx及其简单：
apt install nginx
这个时候如果发现终端不动了，没啥反应，其实是Nginx已经启动了，浏览器输入地址看看是不是能看到nginx欢迎页。
下一步给nginx设置自己的主页
按照参考博客给出的思路，先建立一个文件夹作为nginx访问目录。比如/www/static-web
然后给自己的目的设置一个nginx配置文件，配置文件地址
cd /etc/nginx/conf.d/
然后新建一个static-hello.conf
写进以下内容：
server { server_name = 89.33.194.100; // 你自己的地址或者域名 root /root/www/static-web; // nginx访问目录 index index.html; location ~* ^.+\.(jpg|jpeg|gif|png|ico|css|js|pdf|txt){ root /root/www/static-web/; } }  然后重启nginx
nginx -s reload
我在浏览器访问了一下自己的地址，发现403 Forbidden。故排查之。
查看nginx错误信息
cat /var/log/nginx/error.log
得到这样的信息
2020/04/08 23:43:58 [notice] 1390#1390: signal process started 2020/04/08 23:44:10 [error] 1391#1391: *4 &amp;quot;/root/www/static-web/index.html&amp;quot; is forbidden (13: Permission denied), client: 171.41.91.51, server: =, request: &amp;quot;GET / HTTP/1.</description>
    </item>
    
    <item>
      <title>IFE js.util</title>
      <link>https://zecoo.github.io/hugo/posts/static-web/ife-js-util/</link>
      <pubDate>Tue, 31 Mar 2020 11:37:07 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/static-web/ife-js-util/</guid>
      <description>task1的时候我还能勉强用自己的想法写，html的展示效果达到了就好。
但是到了task2的时候，js基础还是不牢啊，基本上每道题都要看下别人的博客。虽然有点low，但是还是秉着一股劲往前冲，后面再来捡技术细节的思路，不丢人的。
一趟捣鼓下来，JS部分一共就5个板块：
 js基础：数据结构、对象等 dom（html树形结构操作） ajax（和服务器交互，部分刷新页面） jQuery（更方便操作dom和ajax） nodejs（暂时不学习）  接下来总结一下自己的捣鼓过程吧（不包含技术细节）
任务2 JS基础 判断数据类型。 用Objexct.prototype来判断
深克隆。 如果直接var copy = src就是浅复制，所以要用递归的形式。
数组相关操作 1 simpleTrim。这种问题以前从来没接触过，不会写正常2333。for循环判断分别从前和从后面判断时候有空字符
2 trim。正则表达式直接把空字符给替换掉
正则表达式 这是我第几次学习正则表达式啦？？
任务3 Dom 到这里最好还是结合html页面来学习，直接上来写老夫实在是无处下手。
任务4 Event 同dom
任务5 Bom cookie的设置和获取。
以前只知道cookie是什么，现在知道cookie长什么样了怎么搞一个。
任务6 Ajax emmm自己写一个简单的，讲道理，其实是xmlhttp的使用，和ajax没有什么关系。</description>
    </item>
    
    <item>
      <title>IFE Task0001 Log</title>
      <link>https://zecoo.github.io/hugo/posts/static-web/ife-task0001-log/</link>
      <pubDate>Sun, 01 Mar 2020 17:39:45 +0800</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/static-web/ife-task0001-log/</guid>
      <description>我记录一下ife其他几个页面。一共这么几个页面
 index.html post.html archive.html about.html  如果自己写的话，除了index.html，其他几个页面都有或多多少的问题我写不出来。 一个一个说吧。
Index.html  banner有三个部分，一个是logo，一个是站内其他链接，最后一个是git的logo。这三个部分要显示在水平的一行，这里其实是运用到了float，只要把三个部分都设置为float，就可以变成一行了。感觉有点像把div改成了块内元素一样，也就是变成了span。 一般banner的链接都是用list改成水平，改成水平的方法有两个，一个是float，另一个是display inline-block 我想让这三部分，随着页面的改变，位置不要定死，原来margin-left之类的也可以用百分比来表示，就很舒服了。 center是一个大的bg，bg上面有一个透明度的方形显示文字，放bg的时候遇到了以前就遇到的问题，比如默认是重复的，而且不能充满div。这两个问题代码很好解决。 至于透明度的方形，彻底让我对position这个元素有了一定的理解。absolute、fixed、relative分别代表什么。 box部分是三个卡片，卡片里有图片和文字。三个卡片并列其实也挺好写，好像用inline-block就可以实现，水平垂直居中什么的也都是现成的，不过写好了之后再看要求里面有一个是卡片的高度随文字内容自适应。 遂百度之，发现用display table可以解决这个问题，但是table是占满整个div的，不过也好解决，用一大一小div就解决了。 圆形的头像，这个做起来也好简单啊，图片的radius改一下就可以了。 intro部分其实不用display来写，比较常规。如果需要居中之类的工作，用display明显是要方便很多的。 最后一点，如果用flex来布局，flex里面的每个元素的宽度都是以最宽的那个为标准。这时候想要居中的话可以考虑用text-align center解决。这是最后那个小logo的居中问题。  Post.html 在开始写post.html之前我在GitHub上down了几个其他人的ife作业，然后发现我这个代码真的是稀烂…最基本的有这么几个问题：
 文件的结构，ife里强调了，但是我没有遵守。 div的命名方式。navbar，navbar-menu、profile之类的 class和id的区别 nav和footer是html的元素，可以不用div写 html的基本框架应该是navbar、banner、content、footer  然后我找到了一个极佳的对比例子。就是DIYgod，当我看到他就是RSSHub的发起者的时候，我懵逼了。他也就大我三届而已，而且还是武理的，我简直太菜了。。酸归酸，看DIYgod大神的前端页面。能学到很多东西：
 html的其他默认元素：header、section、article、nav的使用 日历写起来其实就是一个table view tag-graph就更简单了，字体设几个不同的大小就可以 一个简单的单词，换一个字体就能变成logo一般的存在  然后记录一下写 blog.html的时候遇到的坑
 blog应该是一个简单的双列布局。双列布局的形式有哪些来着？我是用百分比的形式来布局的。要求用980px，我不太喜欢 table设置了宽高之后，cell变大，那么cell里面字的间距自然就大了 有时候会遇到给div里面子元素加padding之后，div的宽度哪怕设好了，还是会超出来。这个时候要设置一下box-sizing=border-content a写在div外面，就把整个div变成了链接。 我现在使用自适应的方法太简陋了，@media (maxwidth=980) {.div { display=none} }  Archive.html 这个页面我被卡住了。本来一个瀑布流我可以百度，用flex或者用column来解决，但是ife的作业的瀑布流里偏偏有一个比较大的块，是一个这样的结构
[ + ][ ][ ]
[ ][ ][ ][ ]
[ ][ ][ ][ ]</description>
    </item>
    
    <item>
      <title></title>
      <link>https://zecoo.github.io/hugo/posts/metrics/%E5%8F%82%E8%80%83/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zecoo.github.io/hugo/posts/metrics/%E5%8F%82%E8%80%83/</guid>
      <description>参考 https://www.cnblogs.com/lidawn/p/10230903.html （将span很详细）</description>
    </item>
    
  </channel>
</rss>